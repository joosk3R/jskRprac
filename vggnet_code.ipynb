{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwpI3DszkonbSxH1LcxLR6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joosk3R/jskRprac/blob/main/vggnet_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKWpmvh6zWLI",
        "outputId": "975f95e3-ce91-4102-a196-37404930a0bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at vggnet\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('vggnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import package\n",
        "\n",
        "# model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# dataset and transformation\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# display images\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# utils\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "import time\n",
        "import copy\n",
        "\n",
        "\n",
        "# specify a data path\n",
        "path2data = '/content/vggnet/MyDrive/data'\n",
        "\n",
        "# if not exists the path, make the directory\n",
        "if not os.path.exists(path2data):\n",
        "    os.mkdir(path2data)\n",
        "\n",
        "# load dataset\n",
        "train_ds = datasets.STL10(path2data, split='train', download=True, transform=transforms.ToTensor())\n",
        "val_ds = datasets.STL10(path2data, split='test', download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "w18iW38nzatt",
        "outputId": "a5d71c22-2031-4834-9167-90552571ba31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1292e8ac068b>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTL10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath2data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTL10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath2data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/stl10.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, folds, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset not found or corrupted. You can use download=True to download it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/stl10.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files already downloaded and verified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/stl10.py\u001b[0m in \u001b[0;36m_check_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_list\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcheck_integrity\u001b[0;34m(fpath, md5)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcheck_md5\u001b[0;34m(fpath, md5, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcalculate_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcalculate_md5\u001b[0;34m(fpath, chunk_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mmd5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mmd5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# check train_ds\n",
        "img, _ = train_ds[1]\n",
        "print(img.shape)\n",
        "\n",
        "print(len(train_ds))\n",
        "print(len(val_ds))"
      ],
      "metadata": {
        "id": "ovYk-NLozdxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To normalize the dataset, calculate the mean and std\n",
        "train_meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in train_ds]\n",
        "train_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in train_ds]\n",
        "\n",
        "train_meanR = np.mean([m[0] for m in train_meanRGB])\n",
        "train_meanG = np.mean([m[1] for m in train_meanRGB])\n",
        "train_meanB = np.mean([m[2] for m in train_meanRGB])\n",
        "train_stdR = np.mean([s[0] for s in train_stdRGB])\n",
        "train_stdG = np.mean([s[1] for s in train_stdRGB])\n",
        "train_stdB = np.mean([s[2] for s in train_stdRGB])\n",
        "\n",
        "\n",
        "val_meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in val_ds]\n",
        "val_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in val_ds]\n",
        "\n",
        "val_meanR = np.mean([m[0] for m in val_meanRGB])\n",
        "val_meanG = np.mean([m[1] for m in val_meanRGB])\n",
        "val_meanB = np.mean([m[2] for m in val_meanRGB])\n",
        "\n",
        "val_stdR = np.mean([s[0] for s in val_stdRGB])\n",
        "val_stdG = np.mean([s[1] for s in val_stdRGB])\n",
        "val_stdB = np.mean([s[2] for s in val_stdRGB])\n",
        "\n",
        "print(train_meanR, train_meanG, train_meanB)\n",
        "print(val_meanR, val_meanG, val_meanB)\n",
        ""
      ],
      "metadata": {
        "id": "_jJPErfbzmip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the image transformation\n",
        "# using FiveCrop, normalize, horizontal reflection\n",
        "train_transformer = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Resize(224),\n",
        "                    transforms.Normalize([train_meanR, train_meanG, train_meanB], [train_stdR, train_stdG, train_stdB]),\n",
        "])\n",
        "\n",
        "# test_transformer = transforms.Compose([\n",
        "#                     transforms.ToTensor(),\n",
        "#                     transforms.Resize(224),\n",
        "#                     transforms.Normalize([train_meanR, train_meanG, train_meanB], [train_stdR, train_stdG, train_stdB]),\n",
        "# ])\n",
        "\n",
        "# apply transformation\n",
        "train_ds.transform = train_transformer\n",
        "val_ds.transform = train_transformer"
      ],
      "metadata": {
        "id": "EugH-YyxznZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display transformed sample images\n",
        "\n",
        "def show(imgs, y=None, color=True):\n",
        "    # for i, img in enumerate(imgs):\n",
        "    #     npimg = img.numpy()\n",
        "    #     npimg_tr = np.transpose(npimg, (1, 2, 0))\n",
        "    #     plt.subplot(1, imgs.shape[0], i+1)\n",
        "    #     plt.imshow(npimg_tr)\n",
        "\n",
        "    npimg = imgs.numpy()\n",
        "    npimg_tr = np.transpose(npimg, (1, 2, 0))\n",
        "    plt.imshow(npimg_tr)\n",
        "\n",
        "    # plt.imshow(npimg_tr)\n",
        "    if y is not None:\n",
        "        plt.title('labels: ' + str(y))\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# pick a random sample image\n",
        "rnd_inds = int(np.random.randint(0, len(train_ds), 1))\n",
        "img, label = train_ds[rnd_inds]\n",
        "print('images indices: ', rnd_inds)\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "show(img)\n",
        "\n",
        "\n",
        "# create dataloader\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "y5_5k3Y0zskm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG type dict\n",
        "# int : output chnnels after conv layer\n",
        "# 'M' : max pooling layer\n",
        "VGG_types = {\n",
        "    'VGG11' : [64, 'M', 128, 'M', 256, 256, 'M', 512,512, 'M',512,512,'M'],\n",
        "    'VGG13' : [64,64, 'M', 128, 128, 'M', 256, 256, 'M', 512,512, 'M', 512,512,'M'],\n",
        "    'VGG16' : [64,64, 'M', 128, 128, 'M', 256, 256,256, 'M', 512,512,512, 'M',512,512,512,'M'],\n",
        "    'VGG19' : [64,64, 'M', 128, 128, 'M', 256, 256,256,256, 'M', 512,512,512,512, 'M',512,512,512,512,'M']\n",
        "}\n",
        "\n",
        "\n",
        "# define VGGnet class\n",
        "class VGGnet(nn.Module):\n",
        "    def __init__(self, model, in_channels=3, num_classes=10, init_weights=True):\n",
        "        super(VGGnet,self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        # create conv_layers corresponding to VGG type\n",
        "        self.conv_layers = self.create_conv_laters(VGG_types[model])\n",
        "\n",
        "        self.fcs = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "        # weight initialization\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "        x = self.fcs(x)\n",
        "        return x\n",
        "\n",
        "    # define weight initialization function\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    # define a function to create conv layer taken the key of VGG_type dict\n",
        "    def create_conv_laters(self, architecture):\n",
        "        layers = []\n",
        "        in_channels = self.in_channels # 3\n",
        "\n",
        "        for x in architecture:\n",
        "            if type(x) == int: # int means conv layer\n",
        "                out_channels = x\n",
        "\n",
        "                layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                     kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU()]\n",
        "                in_channels = x\n",
        "            elif x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))]\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "# define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# creat VGGnet object\n",
        "model = VGGnet('VGG16', in_channels=3, num_classes=10, init_weights=True).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "nkMKE_P6zuY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(3, 224, 224), device=device.type)"
      ],
      "metadata": {
        "id": "X_8c_YQDzwpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "opt = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# get learning rate\n",
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "current_lr = get_lr(opt)\n",
        "print('current lr={}'.format(current_lr))\n",
        "\n",
        "# define learning rate scheduler\n",
        "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "# lr_scheduler = CosineAnnealingLR(opt, T_max=2, eta_min=1e-5)\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "lr_scheduler = StepLR(opt, step_size=30, gamma=0.1)"
      ],
      "metadata": {
        "id": "BiuogbuBzyct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics_batch(output, target):\n",
        "    # get output class\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "    # compare output class with target class\n",
        "    corrects=pred.eq(target.view_as(pred)).sum().item()\n",
        "    return corrects\n",
        "\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "\n",
        "    # get loss\n",
        "    loss = loss_func(output, target)\n",
        "\n",
        "    # get performance metric\n",
        "    metric_b = metrics_batch(output,target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    return loss.item(), metric_b\n",
        "\n",
        "def loss_epoch(model,loss_func,dataset_dl,sanity_check=False,opt=None):\n",
        "    running_loss=0.0\n",
        "    running_metric=0.0\n",
        "    len_data=len(dataset_dl.dataset)\n",
        "\n",
        "    for xb, yb in dataset_dl:\n",
        "        # move batch to device\n",
        "        xb=xb.to(device)\n",
        "        yb=yb.to(device)\n",
        "        output = model(xb)\n",
        "        # Five crop : bs, crops, chnnel, h, w\n",
        "        # making dimmension (bs, c, h, w)\n",
        "        # bs, ncrops, c, h, w = xb.size()\n",
        "        # output_=model(xb.view(-1, c, h, w))\n",
        "        # output = output_.view(bs, ncrops, -1).mean(1)\n",
        "\n",
        "        # get loss per batch\n",
        "        loss_b,metric_b=loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "        # update running loss\n",
        "        running_loss+=loss_b\n",
        "\n",
        "        # update running metric\n",
        "        if metric_b is not None:\n",
        "            running_metric+=metric_b\n",
        "\n",
        "        # break the loop in case of sanity check\n",
        "        if sanity_check is True:\n",
        "            break\n",
        "\n",
        "    # average loss value\n",
        "    loss=running_loss/float(len_data)\n",
        "\n",
        "    # average metric value\n",
        "    metric=running_metric/float(len_data)\n",
        "\n",
        "    return loss, metric\n",
        "\n",
        "\n",
        "def train_val(model, params):\n",
        "    # extract model parameters\n",
        "    num_epochs=params[\"num_epochs\"]\n",
        "    loss_func=params[\"loss_func\"]\n",
        "    opt=params[\"optimizer\"]\n",
        "    train_dl=params[\"train_dl\"]\n",
        "    val_dl=params[\"val_dl\"]\n",
        "    sanity_check=params[\"sanity_check\"]\n",
        "    lr_scheduler=params[\"lr_scheduler\"]\n",
        "    path2weights=params[\"path2weights\"]\n",
        "\n",
        "    # history of loss values in each epoch\n",
        "    loss_history={\n",
        "        \"train\": [],\n",
        "        \"val\": [],\n",
        "    }\n",
        "\n",
        "    # histroy of metric values in each epoch\n",
        "    metric_history={\n",
        "        \"train\": [],\n",
        "        \"val\": [],\n",
        "    }\n",
        "\n",
        "    # 가중치를 저장할 때, 코랩 GPU 오류나서 생략했습니다.\n",
        "    # a deep copy of weights for the best performing model\n",
        "    # best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # initialize best loss to a large value\n",
        "    best_loss=float('inf')\n",
        "\n",
        "    # check start time\n",
        "    start_time = time.time()\n",
        "    # main loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # get current learning rate\n",
        "        current_lr=get_lr(opt)\n",
        "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs - 1, current_lr))\n",
        "\n",
        "        # train model on training dataset\n",
        "        model.train()\n",
        "        train_loss, train_metric=loss_epoch(model,loss_func,train_dl,sanity_check,opt)\n",
        "\n",
        "        # collect loss and metric for training dataset\n",
        "        loss_history[\"train\"].append(train_loss)\n",
        "        metric_history[\"train\"].append(train_metric)\n",
        "\n",
        "        # evaluate model on validation dataset\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric=loss_epoch(model,loss_func,val_dl,sanity_check)\n",
        "\n",
        "\n",
        "        # store best model\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            # # store weights into a local file\n",
        "            # torch.save(model.state_dict(), path2weights)\n",
        "            # print(\"Copied best model weights!\")\n",
        "\n",
        "        # collect loss and metric for validation dataset\n",
        "        loss_history[\"val\"].append(val_loss)\n",
        "        metric_history[\"val\"].append(val_metric)\n",
        "\n",
        "        # learning rate schedule\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        print(\"train loss: %.6f, dev loss: %.6f, accuracy: %.2f, time: %.4f s\" %(train_loss,val_loss,100*val_metric, time.time()-start_time))\n",
        "        print(\"-\"*10)\n",
        "\n",
        "    ## load best model weights\n",
        "    # model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, loss_history, metric_history\n",
        "\n",
        "\n",
        "# definc the training parameters\n",
        "params_train = {\n",
        "    'num_epochs':100,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':train_dl,\n",
        "    'val_dl':val_dl,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/weights.pt',\n",
        "}\n",
        "\n",
        "# create the directory that stores weights.pt\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSerror:\n",
        "        print('Error')\n",
        "createFolder('./models')\n",
        "\n",
        "\n",
        "# train model\n",
        "model, loss_hist, metric_hist = train_val(model, params_train)"
      ],
      "metadata": {
        "id": "dadHjj00z154"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}