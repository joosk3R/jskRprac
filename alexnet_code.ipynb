{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNn6nuS5kr12h9R2eSvW6p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joosk3R/jskRprac/blob/main/alexnet_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "rc('font', family='AppleGothic')\n",
        "\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ],
      "metadata": {
        "id": "zOOm80BLDmH-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97ISTlJl5Dzj",
        "outputId": "80e21b5f-e498-4bf8-d303-8b8d666c0839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at alexnet; to attempt to forcibly remount, call drive.mount(\"alexnet\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('alexnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matplotlib 한글 폰트 오류 문제 해결\n",
        "from matplotlib import font_manager, rc\n",
        "rc('font', family='AppleGothic')"
      ],
      "metadata": {
        "id": "DWrWf4Sh6eNp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loding training dataset\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import os"
      ],
      "metadata": {
        "id": "TRL5_zff6DVu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path2data = \"/data\"\n",
        "if not os.path.exists(path2data):\n",
        "  os.mkdir(path2data)"
      ],
      "metadata": {
        "id": "Ce1VQfG56qlt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transformer = transforms.Compose([transforms.ToTensor()])\n",
        "train_ds= datasets.STL10(path2data, split='train',download=True, transform = data_transformer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fedILFW46zcQ",
        "outputId": "c34d0a11-7e09-4932-dd91-e679835f8115"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWKmBhUL9xpH",
        "outputId": "1a37fe4a-9d56-43b7-8b2e-6c8126e7f0d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 3, 96, 96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLUrbyj9_E9a",
        "outputId": "92dd27df-b169-42f8-a8c5-83f27cb0c64e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.5059, 0.4863, 0.5412,  ..., 0.5490, 0.5490, 0.5608],\n",
              "          [0.5176, 0.4863, 0.5020,  ..., 0.5686, 0.5647, 0.5882],\n",
              "          [0.5176, 0.5020, 0.5059,  ..., 0.5882, 0.5804, 0.5843],\n",
              "          ...,\n",
              "          [0.6863, 0.4392, 0.5176,  ..., 0.7686, 0.6510, 0.5412],\n",
              "          [0.5804, 0.4510, 0.3843,  ..., 0.6157, 0.5020, 0.6980],\n",
              "          [0.5686, 0.6314, 0.5647,  ..., 0.5725, 0.5922, 0.7608]],\n",
              " \n",
              "         [[0.5490, 0.5216, 0.5647,  ..., 0.5451, 0.5451, 0.5451],\n",
              "          [0.5608, 0.5216, 0.5373,  ..., 0.5490, 0.5529, 0.5804],\n",
              "          [0.5569, 0.5412, 0.5451,  ..., 0.5765, 0.5804, 0.5765],\n",
              "          ...,\n",
              "          [0.6353, 0.4314, 0.4627,  ..., 0.6941, 0.5725, 0.4745],\n",
              "          [0.4941, 0.4235, 0.3412,  ..., 0.5373, 0.4275, 0.5765],\n",
              "          [0.4706, 0.5608, 0.5176,  ..., 0.5020, 0.5098, 0.6431]],\n",
              " \n",
              "         [[0.2863, 0.2667, 0.3294,  ..., 0.3294, 0.3137, 0.3294],\n",
              "          [0.3098, 0.2784, 0.3059,  ..., 0.3569, 0.3373, 0.3686],\n",
              "          [0.3176, 0.3020, 0.3059,  ..., 0.3725, 0.3569, 0.3608],\n",
              "          ...,\n",
              "          [0.4667, 0.2706, 0.3373,  ..., 0.5333, 0.4314, 0.3255],\n",
              "          [0.3451, 0.3059, 0.2706,  ..., 0.3882, 0.2824, 0.4510],\n",
              "          [0.3255, 0.4118, 0.3843,  ..., 0.3686, 0.3569, 0.4824]]]),\n",
              " 5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test0_ds = datasets.STL10(path2data, split= 'test', download = True, transform = data_transformer)\n",
        "print(test0_ds.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31WzlDOD7VVR",
        "outputId": "180d6020-519b-4b6e-84f4-b1c4316aa77f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "(8000, 3, 96, 96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in train_ds]\n",
        "stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in train_ds]\n",
        "\n",
        "\n",
        "meanR = np.mean([m[0] for m in meanRGB])\n",
        "meanG = np.mean([m[1] for m in meanRGB])\n",
        "meanB = np.mean([m[2] for m in meanRGB])\n",
        "\n",
        "stdR = np.mean([s[0] for s in stdRGB])\n",
        "stdG = np.mean([s[1] for s in stdRGB])\n",
        "stdB = np.mean([s[2] for s in stdRGB])"
      ],
      "metadata": {
        "id": "MXazF8-W95ak"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(meanR, meanG, meanB)\n",
        "print(stdR, stdG, stdB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD2WfqKn-HI3",
        "outputId": "337b3d17-6a96-4721-8bde-33c89fdee624"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4467106 0.43980986 0.40664646\n",
            "0.22414584 0.22148906 0.22389975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transformer = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([meanR,meanG,meanB],[stdR,stdG,stdB]),\n",
        "    transforms.Resize(227)\n",
        "])\n",
        "\n",
        "test_transformer = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB]),\n",
        "                transforms.Resize(227)\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "mWm7H9RS_u8M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.transform = train_transformer\n",
        "test0_ds.transform = test_transformer"
      ],
      "metadata": {
        "id": "ETnPkoR6_vTX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, _ = train_ds[1]\n",
        "print(img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn24LP_YBITn",
        "outputId": "f4e7b889-9a33-4be7-c7bf-6199ca44719c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 227, 227])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "LgXKdLG3BRco"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show(img, y=None, color=True):\n",
        "\n",
        "  npimg = img.numpy()\n",
        "  npimg_tr = np.transpose(npimg, (1,2,0))\n",
        "  plt.imshow(npimg_tr)\n",
        "\n",
        "  if y is not None:\n",
        "    plt.title(\"labels: \"+ str(y))\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "rnd_inds = int(np.random.randint(0,len(train_ds),1))\n",
        "print(rnd_inds)\n",
        "img, label = train_ds[rnd_inds]\n",
        "print('images indices: ' , rnd_inds)\n",
        "\n",
        "plt.figure(figsize =(10,10))\n",
        "show(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QnJCJKuoBmhy",
        "outputId": "92523d38-3337-4936-f471-e9e525b129cd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2732\n",
            "images indices:  2732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "y_train = [y for _,y in train_ds]\n",
        "counter_train = collections.Counter(y_train)\n",
        "print(counter_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fr6WfVLDV0m",
        "outputId": "a265c531-2f1d-4398-d03a-f4e9d555c755"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1: 500, 5: 500, 6: 500, 3: 500, 9: 500, 7: 500, 4: 500, 8: 500, 0: 500, 2: 500})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits =1 , test_size = 0.2 , random_state = 0)\n",
        "\n",
        "indices =list(range(len(test0_ds)))\n",
        "y_test0 = [y for _,y in test0_ds]\n",
        "\n",
        "for test_index, val_index in sss.split(indices, y_test0):\n",
        "  print('test : ', len(test_index), 'val : ',len(val_index))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL0X37_CD7ml",
        "outputId": "57a577a1-cacb-4887-9724-71c932015d2a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test :  6400 val :  1600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create two datasets from test0_ds\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# if test0_ds is updated, val_ds and test_ds are updated\n",
        "# because val_ds and test_ds are a subset of test0_ds\n",
        "val_ds = Subset(test0_ds, val_index)\n",
        "test_ds = Subset(test0_ds, test_index)"
      ],
      "metadata": {
        "id": "L8pw1ejiFMpq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of images per calss in val_ds and test_ds\n",
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "y_test = [y for _, y in test_ds]\n",
        "y_val = [y for _, y in val_ds]\n",
        "\n",
        "counter_test = collections.Counter(y_test)\n",
        "counter_val = collections.Counter(y_val)\n",
        "print(counter_test)\n",
        "print(counter_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CthM7zFjFcVO",
        "outputId": "2765d77e-3492-4334-fc14-bc8fc449db37"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({6: 640, 0: 640, 4: 640, 5: 640, 9: 640, 2: 640, 3: 640, 1: 640, 7: 640, 8: 640})\n",
            "Counter({2: 160, 8: 160, 3: 160, 6: 160, 4: 160, 1: 160, 5: 160, 9: 160, 0: 160, 7: 160})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dl = DataLoader(train_ds, batch_size = 32 , shuffle = True)\n",
        "val_dl = DataLoader(val_ds, batch_size = 32 , shuffle = True)\n",
        "\n",
        "for x,y in train_dl:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break\n",
        "\n",
        "for x,y in val_dl:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxjJFt7XFeKP",
        "outputId": "21032ff7-9f85-4647-c8fa-39a3bbd44b38"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 227, 227])\n",
            "torch.Size([32])\n",
            "torch.Size([32, 3, 227, 227])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mArpz1HANqfE",
        "outputId": "3854f8ef-db18-4607-9261-afc70ad0f703"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet,self).__init__()\n",
        "        # input size : (b x 3 x 227 x 227)\n",
        "        # 논문에는 image 크기가 224 pixel이라고 나와 있지만, 오타입니다.\n",
        "        # 227x227을 사용합니다.\n",
        "\n",
        "        # Conv layer\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0), # (b x 96 x 55 x 55)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # (b x 96 x 27 x 27)\n",
        "\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2), # (b x 256 x 27 x 27)\n",
        "            nn.ReLU(),\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # (b x 256 x 13 x 13)\n",
        "\n",
        "            nn.Conv2d(256, 384, 3, 1, 1), # (b x 384 x 13 x 13)\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(384, 384, 3, 1, 1), # (b x 384 x 13 x 13)\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(384, 256, 3, 1, 1), # (b x 256 x 13 x 13)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2), # (b x 256 x 6 x 6)\n",
        "        )\n",
        "\n",
        "        # fc layer\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5, inplace=True),\n",
        "            nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5, inplace=True),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=num_classes),\n",
        "        )\n",
        "\n",
        "        # weight initialization\n",
        "        self.init_weight()\n",
        "\n",
        "    # define weight initialization function\n",
        "    def init_weight(self):\n",
        "        for layer in self.net:\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
        "                nn.init.constant_(layer.bias, 0)\n",
        "        # in paper, initialize bias to 1 for conv2, 4, 5 layer\n",
        "        nn.init.constant_(self.net[4].bias, 1)\n",
        "        nn.init.constant_(self.net[10].bias, 1)\n",
        "        nn.init.constant_(self.net[12].bias, 1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.net(x)\n",
        "        x = x.view(-1, 256 * 6* 6)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        ""
      ],
      "metadata": {
        "id": "aUgdRlvJNiw1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the model\n",
        "model = AlexNet().to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-t0pGmTMS5W",
        "outputId": "6d801067-ac09-4e0e-d335-8f5d9f47b84a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (net): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (5): ReLU()\n",
            "    (6): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
            "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU()\n",
            "    (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU()\n",
            "    (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU()\n",
            "    (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=True)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.5, inplace=True)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get the model summary\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(3, 227, 227), device=device.type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMn9NU8YMlc0",
        "outputId": "fffb0143-3709-4854-b846-3f60eb88d270"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            " LocalResponseNorm-3           [-1, 96, 55, 55]               0\n",
            "         MaxPool2d-4           [-1, 96, 27, 27]               0\n",
            "            Conv2d-5          [-1, 256, 27, 27]         614,656\n",
            "              ReLU-6          [-1, 256, 27, 27]               0\n",
            " LocalResponseNorm-7          [-1, 256, 27, 27]               0\n",
            "         MaxPool2d-8          [-1, 256, 13, 13]               0\n",
            "            Conv2d-9          [-1, 384, 13, 13]         885,120\n",
            "             ReLU-10          [-1, 384, 13, 13]               0\n",
            "           Conv2d-11          [-1, 384, 13, 13]       1,327,488\n",
            "             ReLU-12          [-1, 384, 13, 13]               0\n",
            "           Conv2d-13          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-14          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-15            [-1, 256, 6, 6]               0\n",
            "          Dropout-16                 [-1, 9216]               0\n",
            "           Linear-17                 [-1, 4096]      37,752,832\n",
            "             ReLU-18                 [-1, 4096]               0\n",
            "          Dropout-19                 [-1, 4096]               0\n",
            "           Linear-20                 [-1, 4096]      16,781,312\n",
            "             ReLU-21                 [-1, 4096]               0\n",
            "           Linear-22                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 58,322,314\n",
            "Trainable params: 58,322,314\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 14.72\n",
            "Params size (MB): 222.48\n",
            "Estimated Total Size (MB): 237.79\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# check weight initialization\n",
        "for p in model.parameters():\n",
        "    print(p)\n",
        "    break\n",
        ""
      ],
      "metadata": {
        "id": "LO8Qd7ZlN8t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss(reduction ='sum')\n",
        "from torch import optim\n",
        "# opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "opt = optim.Adam(model.parameters(), lr =0.01)\n",
        "\n",
        "\n",
        "# read the current value of the learning rate using the following function\n",
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR # define lr_scheduler : 1/10 per 10 epochs\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(opt, step_size=30, gamma=0.1)"
      ],
      "metadata": {
        "id": "4L-5ya4zOF7H"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics_batch(output, target):\n",
        "  pred = output.argmax(dim=1 , keepdim= True)\n",
        "  corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "  return corrects"
      ],
      "metadata": {
        "id": "0ZdZ7D7OPyLt"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to compute the loss value per mini-batch\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "    loss = loss_func(output, target)\n",
        "\n",
        "    metric_b = metrics_batch(output, target)\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    return loss.item(), metric_b"
      ],
      "metadata": {
        "id": "hb_gDJcFQVxe"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# develop a function to compute the loss value and the performance metric for the epoch\n",
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "    running_loss = 0\n",
        "    running_metric = 0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "\n",
        "    for xb, yb in dataset_dl:\n",
        "        # move batcch to device\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        # get model output\n",
        "        output = model(xb)\n",
        "\n",
        "        # get loss per batch\n",
        "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "        # update running loss\n",
        "        running_loss += loss_b\n",
        "        # update running metric\n",
        "        if metric_b is not None:\n",
        "            running_metric += metric_b\n",
        "\n",
        "        # break the loop in case of sanity check\n",
        "        if sanity_check is True:\n",
        "            break\n",
        "\n",
        "    # average loss value and metric value\n",
        "    loss = running_loss / float(len_data)\n",
        "    metric = running_metric / float(len_data)\n",
        "    return loss, metric\n",
        ""
      ],
      "metadata": {
        "id": "jKZBwbh4Qai_"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "# develop train_val function\n",
        "def train_val(model, params):\n",
        "    # extract model parameters\n",
        "    num_epochs = params['num_epochs']\n",
        "    loss_func = params['loss_func']\n",
        "    opt = params['optimizer']\n",
        "    train_dl = params['train_dl']\n",
        "    val_dl = params['val_dl']\n",
        "    sanity_check = params['sanity_check']\n",
        "    lr_scheduler = params['lr_scheduler']\n",
        "    path2weights = params['path2weights']\n",
        "\n",
        "    # keep a history of the loss and the metric value\n",
        "    loss_history = {\n",
        "        'train': [],\n",
        "        'val': [],\n",
        "    }\n",
        "\n",
        "    metric_history = {\n",
        "        'train': [],\n",
        "        'val': [],\n",
        "    }\n",
        "\n",
        "    # save the best perfirming model\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # initializer the best loss to an infinite value\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # get current learning rate\n",
        "        current_lr = get_lr(opt)\n",
        "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "        # train model on trainin dataset\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "\n",
        "        # collect loss and metric for the training dataset\n",
        "        loss_history['train'].append(train_loss)\n",
        "        metric_history['train'].append(train_metric)\n",
        "\n",
        "        # evaluate model on validation dataset\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
        "\n",
        "        # store the best model\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            # store weights into a local file\n",
        "            torch.save(model.state_dict(), path2weights)\n",
        "            print('Copied best model weights')\n",
        "\n",
        "        # collect loss and metric for validation dataset\n",
        "        loss_history[\"val\"].append(val_loss)\n",
        "        metric_history[\"val\"].append(val_metric)\n",
        "\n",
        "        # update the learning rate\n",
        "        lr_scheduler.step()\n",
        "        if current_lr != get_lr(opt):\n",
        "            print('Loading best model weights!')\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        # print the loss and accuracy values and return the trained model\n",
        "        print('train loss: %.6f, dev loss: %.6f, accuracy: %.2f, time: %.4f s' %(train_loss, val_loss, 100*val_metric, time.time()-start_time))\n",
        "        print('-'*10)\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, loss_history, metric_history\n",
        ""
      ],
      "metadata": {
        "id": "WjUtPzpcQkpM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the training parameters\n",
        "params_train = {\n",
        "    'num_epochs':3,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':train_dl,\n",
        "    'val_dl':val_dl,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/weights.pt',\n",
        "}\n",
        "\n",
        "# check the directory to save weights.pt\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSerror:\n",
        "        print('Error')\n",
        "createFolder('./models')"
      ],
      "metadata": {
        "id": "DysTz8G6Qm34"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, loss_hist, metric_hist = train_val(model, params_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "1GAZ20TrQpOS",
        "outputId": "fad105cf-beee-47d7-f9b9-54d4a6a6c174"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/2, current lr=0.01\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-40a68c4f9fe2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-b0b2f1455c9f>\u001b[0m in \u001b[0;36mtrain_val\u001b[0;34m(model, params)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# train model on trainin dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanity_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# collect loss and metric for the training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-97973afc763b>\u001b[0m in \u001b[0;36mloss_epoch\u001b[0;34m(model, loss_func, dataset_dl, sanity_check, opt)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# get loss per batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# update running loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-bed212859964>\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(loss_func, output, target, opt)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [32, 4096]], which is output 0 of ReluBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the loss function\n",
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "\n",
        "# define the optimizer\n",
        "from torch import optim\n",
        "# opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "opt = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "# read the current value of the learning rate using the following function\n",
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "# define lr_scheduler : 1/10 per 10 epochs\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(opt, step_size=30, gamma=0.1)\n",
        "\n",
        "\n",
        "# define a function to count the number of correct predictions per mini-batch\n",
        "def metrics_batch(output, target):\n",
        "    # get output class\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "    # compare output class with target class\n",
        "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "    return corrects\n",
        "\n",
        "\n",
        "# define a function to compute the loss value per mini-batch\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "    loss = loss_func(output, target)\n",
        "\n",
        "    metric_b = metrics_batch(output, target)\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    return loss.item(), metric_b\n",
        "\n",
        "\n",
        "# develop a function to compute the loss value and the performance metric for the epoch\n",
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "    running_loss = 0\n",
        "    running_metric = 0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "\n",
        "    for xb, yb in dataset_dl:\n",
        "        # move batcch to device\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        # get model output\n",
        "        output = model(xb)\n",
        "\n",
        "        # get loss per batch\n",
        "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "        # update running loss\n",
        "        running_loss += loss_b\n",
        "        # update running metric\n",
        "        if metric_b is not None:\n",
        "            running_metric += metric_b\n",
        "\n",
        "        # break the loop in case of sanity check\n",
        "        if sanity_check is True:\n",
        "            break\n",
        "\n",
        "    # average loss value and metric value\n",
        "    loss = running_loss / float(len_data)\n",
        "    metric = running_metric / float(len_data)\n",
        "    return loss, metric\n",
        "\n",
        "\n",
        "import time\n",
        "import copy\n",
        "\n",
        "# develop train_val function\n",
        "def train_val(model, params):\n",
        "    # extract model parameters\n",
        "    num_epochs = params['num_epochs']\n",
        "    loss_func = params['loss_func']\n",
        "    opt = params['optimizer']\n",
        "    train_dl = params['train_dl']\n",
        "    val_dl = params['val_dl']\n",
        "    sanity_check = params['sanity_check']\n",
        "    lr_scheduler = params['lr_scheduler']\n",
        "    path2weights = params['path2weights']\n",
        "\n",
        "    # keep a history of the loss and the metric value\n",
        "    loss_history = {\n",
        "        'train': [],\n",
        "        'val': [],\n",
        "    }\n",
        "\n",
        "    metric_history = {\n",
        "        'train': [],\n",
        "        'val': [],\n",
        "    }\n",
        "\n",
        "    # save the best perfirming model\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # initializer the best loss to an infinite value\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # get current learning rate\n",
        "        current_lr = get_lr(opt)\n",
        "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "        # train model on trainin dataset\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "\n",
        "        # collect loss and metric for the training dataset\n",
        "        loss_history['train'].append(train_loss)\n",
        "        metric_history['train'].append(train_metric)\n",
        "\n",
        "        # evaluate model on validation dataset\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
        "\n",
        "        # store the best model\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            # store weights into a local file\n",
        "            torch.save(model.state_dict(), path2weights)\n",
        "            print('Copied best model weights')\n",
        "\n",
        "        # collect loss and metric for validation dataset\n",
        "        loss_history[\"val\"].append(val_loss)\n",
        "        metric_history[\"val\"].append(val_metric)\n",
        "\n",
        "        # update the learning rate\n",
        "        lr_scheduler.step()\n",
        "        if current_lr != get_lr(opt):\n",
        "            print('Loading best model weights!')\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        # print the loss and accuracy values and return the trained model\n",
        "        print('train loss: %.6f, dev loss: %.6f, accuracy: %.2f, time: %.4f s' %(train_loss, val_loss, 100*val_metric, time.time()-start_time))\n",
        "        print('-'*10)\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, loss_history, metric_history\n",
        "\n",
        "\n",
        "# define the training parameters\n",
        "params_train = {\n",
        "    'num_epochs':3,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':train_dl,\n",
        "    'val_dl':val_dl,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/weights.pt',\n",
        "}\n",
        "\n",
        "# check the directory to save weights.pt\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSerror:\n",
        "        print('Error')\n",
        "createFolder('./models')\n",
        ""
      ],
      "metadata": {
        "id": "1378KTx0Qq4l"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #train model\n",
        "model, loss_hist, metric_hist = train_val(model, params_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "FtgWIFaPRf4r",
        "outputId": "8a716240-f5fa-4111-8aeb-f2ae6380377f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/2, current lr=0.01\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-dd11394caaac>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-65-97f43b2666c0>\u001b[0m in \u001b[0;36mtrain_val\u001b[0;34m(model, params)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# train model on trainin dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanity_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# collect loss and metric for the training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-97f43b2666c0>\u001b[0m in \u001b[0;36mloss_epoch\u001b[0;34m(model, loss_func, dataset_dl, sanity_check, opt)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# get loss per batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# update running loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-97f43b2666c0>\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(loss_func, output, target, opt)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [32, 4096]], which is output 0 of ReluBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "왜 안되는지 모르곘넹..."
      ],
      "metadata": {
        "id": "yaNdF-mGR_oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "PSPCL2UfUhdO"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device   # cuda 지정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldzDemdjU7Kl",
        "outputId": "674616aa-20e2-4254-dd0b-188b319bf5f6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #논문 5. Details of learning 참고 parameter\n",
        "batch_size = 128\n",
        "momentum = 0.9\n",
        "lr_decay = 0.0005\n",
        "lr_init = 0.01\n",
        "image_dim = 227    # pixels\n",
        "num_classes = 1000   # 1000개의 class 지정\n",
        "device_ids = [0, 1, 2, 3]"
      ],
      "metadata": {
        "id": "GMydORaVU8d7"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "\n",
        "  def __init__(self, num_classes=1000):\n",
        "    super().__init__()\n",
        "\n",
        "    ##### CNN layers\n",
        "    self.net = nn.Sequential(\n",
        "        # conv1\n",
        "        nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),\n",
        "        nn.ReLU(inplace=True),  # non-saturating function\n",
        "        nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # 논문의 LRN 파라미터 그대로 지정\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        # conv2\n",
        "        nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        # conv3\n",
        "        nn.Conv2d(256, 384, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        # conv4\n",
        "        nn.Conv2d(384, 384, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        # conv5\n",
        "        nn.Conv2d(384, 256, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "    )\n",
        "\n",
        "    ##### FC layers\n",
        "    self.classifier = nn.Sequential(\n",
        "        # fc1\n",
        "        nn.Dropout(p=0.5, inplace=True),\n",
        "        nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\n",
        "        nn.ReLU(inplace=True).\n",
        "        # fc2\n",
        "        nn.Dropout(p=0.5, inplace=True),\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(4096, num_classes),\n",
        "    )\n",
        "\n",
        "    # bias, weight 초기화\n",
        "    def init_bias_weights(self):\n",
        "      for layer in self.net:\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "          nn.init.normal_(layer.weight, mean=0, std=0.01)   # weight 초기화\n",
        "          nn.init.constant_(layer.bias, 0)   # bias 초기화\n",
        "\n",
        "      # conv 2, 4, 5는 bias 1로 초기화\n",
        "      nn.init.constant_(self.net[4].bias, 1)\n",
        "      nn.init.constant_(self.net[10].bias, 1)\n",
        "      nn.init.constant_(self.net[12].bias, 1)\n",
        "\n",
        "    # modeling\n",
        "    def forward(self, x):\n",
        "      x = self.net(x)   # conv\n",
        "      x = x.view(-1, 256*6*6)   # keras의 reshape (텐서 크기 2d 변경)\n",
        "      return self.classifier(x)   # fc"
      ],
      "metadata": {
        "id": "95VYXTP8U8_U"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__== '__main__':\n",
        "  seed = torch.initial_seed()  # seed value 설정\n",
        "  model = AlexNet(num_classes=num_classes).to(device)\n",
        "  model = torch.nn.parallel.DataParallel(model, divice_ids=device_ids)  # 모델 설정\n",
        "  print(model)\n",
        "\n",
        "  # dataset, data loader 설정\n",
        "  dataset = datasets.ImageFolder(TRAIN_IMG_DIR, transforms.Compose([\n",
        "      transforms.CenterCrop(IMAGE_DIM),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "  ]))\n",
        "\n",
        "  dataloader = data.DataLoader(\n",
        "      dataset,\n",
        "      shuffle=True,\n",
        "      pin_memory=True,\n",
        "      num_workers=8,\n",
        "      drop_last=True,\n",
        "      batch_size=batch_size)\n",
        "\n",
        "  # optimizer\n",
        "  optimizer = optim.SGD(\n",
        "      params = model.parameters(),\n",
        "      lr = lr_init,\n",
        "      momentum = momentum,\n",
        "      weight_decay = lr_decay  # lr 점점 감소\n",
        "  )\n",
        "\n",
        "  lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)   # lr 점점 감소\n",
        "\n",
        "  # training\n",
        "  total_steps=1\n",
        "  for epoch in range(num_epochs):\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    for imgs, classes in dataloader:\n",
        "      imgs, classes = imgs.to(device), classes.to(device)\n",
        "\n",
        "      output = alexnet(imgs)\n",
        "      loss = F.cross_entropy(output, classes)  # loss 계산\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()  # backpropa\n",
        "      optimizer.step()  # parameter update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "LiFfF5SGVDkK",
        "outputId": "64530b81-d144-4da9-e852-a2f32326db2c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-543a69d9fd13>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# seed value 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlexNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivice_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 모델 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-3f946743ac84>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# fc2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ReLU' object has no attribute 'nn'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorboardcolab   # tensorboard 설치\n"
      ],
      "metadata": {
        "id": "sTaDXk-zVG7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "재도전"
      ],
      "metadata": {
        "id": "5xyIOucXWL5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4)\n",
        "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1) # conv5와 fc1 사이에 view 들어간다.\n",
        "        self.fc1 = nn.Linear(in_features=256 * 6 * 6, out_features=4096) # fc layer\n",
        "        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
        "        self.fc3 = nn.Linear(in_features=4096, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "\n",
        "        x = x.view(x.size(0), -1) # 4차원을 1차원으로 펼쳐주는 층 (역할) -> flatten\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, p=0.5)\n",
        "\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, p=0.5)\n",
        "\n",
        "        x = F.log_softmax(self.fc3(x), dim=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def transform():\n",
        "        return transforms.Compose([transforms.Resize((227, 227)),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize(mean=(0.1307,), std=(0.3081,))])\n",
        "if __name__ == \"__main__\":\n",
        "    # if gpu is to be used\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    print(\"use_cuda : \", use_cuda)\n",
        "\n",
        "    FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
        "    device= torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "    net = AlexNet().to(device)\n",
        "\n",
        "    X = torch.randn(size=(1, 1, 227, 227)).type(FloatTensor)\n",
        "    print(net(X))\n",
        "    print(summary(net, (1, 227, 227)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGUgWLeLWtyS",
        "outputId": "6cf0e853-61a8-4111-bfb0-2440d91ce3b9"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use_cuda :  True\n",
            "tensor([[-2.2898, -2.2880, -2.3073, -2.2927, -2.3028, -2.3245, -2.3268, -2.2984,\n",
            "         -2.2979, -2.2983]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          11,712\n",
            "            Conv2d-2          [-1, 256, 27, 27]         614,656\n",
            "            Conv2d-3          [-1, 384, 13, 13]         885,120\n",
            "            Conv2d-4          [-1, 384, 13, 13]       1,327,488\n",
            "            Conv2d-5          [-1, 256, 13, 13]         884,992\n",
            "            Linear-6                 [-1, 4096]      37,752,832\n",
            "            Linear-7                 [-1, 4096]      16,781,312\n",
            "            Linear-8                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 58,299,082\n",
            "Trainable params: 58,299,082\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.20\n",
            "Forward/backward pass size (MB): 5.02\n",
            "Params size (MB): 222.39\n",
            "Estimated Total Size (MB): 227.61\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "    # hyper parameter\n",
        "    batch_size = 512\n",
        "    num_epochs = 20\n",
        "    learning_rate = 0.0001\n",
        "\n",
        "    # data load\n",
        "    root = './MNIST_Fashion'\n",
        "    transform = AlexNet.transform()\n",
        "    train_set = datasets.FashionMNIST(root=root, train=True, transform=transform, download=True)\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    test_set = datasets.FashionMNIST(root=root, train=False, transform=transform, download=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "    # if gpu is to be used\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    print(\"use_cuda : \", use_cuda)\n",
        "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "    model = AlexNet().to(device)\n",
        "    criterion = F.nll_loss\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "    def train(model, device, train_loader, optimizer, epoch):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            target = target.type(torch.LongTensor)\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (batch_idx + 1) % 30 == 0:\n",
        "                print(\"Train Epoch:{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "    def test(model, device, test_loader):\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                test_loss += criterion(output, target, reduction='sum').item()\n",
        "                pred = output.max(1, keepdim=True)[1]\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "            test_loss /= len(test_loader.dataset)\n",
        "            print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
        "                test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
        "            print('='*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PRu1ah_WvAd",
        "outputId": "ee20faa3-1272-49ee-b92d-6628e4987b1c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./MNIST_Fashion/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 15853022.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_Fashion/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./MNIST_Fashion/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./MNIST_Fashion/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 271073.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_Fashion/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST_Fashion/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./MNIST_Fashion/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5064142.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_Fashion/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST_Fashion/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./MNIST_Fashion/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 20983748.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_Fashion/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST_Fashion/FashionMNIST/raw\n",
            "\n",
            "use_cuda :  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnBF8q97Wz8s",
        "outputId": "3fc8f320-6fd8-4566-f8ce-70d15eaf95cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:1 [14848/60000 (25%)]\tLoss: 0.820790\n"
          ]
        }
      ]
    }
  ]
}