{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joosk3R/jskRprac/blob/main/%EB%8D%B0%EC%9D%B4%EC%BD%98_%EC%A0%84%ED%99%94%EB%8D%B0%EC%9D%B4%ED%84%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvp7Qh6cR-l0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install optuna\n"
      ],
      "metadata": {
        "id": "YdAJTKhRwyLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "id": "JaGp2pzEBajD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc  ### 이 줄과\n",
        "rc('font', family='AppleGothic') \t\t\t## 이 두 줄을\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "plt.rcParams['font.family'] =  'STIXSizeOneSym'\n",
        "import matplotlib.font_manager as fm\n"
      ],
      "metadata": {
        "id": "6U1g90oCVf96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D_eClJ8va-X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path = '/content/drive/MyDrive/'"
      ],
      "metadata": {
        "id": "x_AWUPQ2T1gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vx8x5O2XH9Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# basic\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "\n",
        "#data analytics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Math\n",
        "import scipy as sp\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#web crawling\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#visualization\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pylab as plb\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sk\n",
        "import seaborn as sns\n",
        "\n",
        "# 브라우저에서 바로 그려지도록\n",
        "%matplotlib inline\n",
        "\n",
        "# 그래프에 retina display 적용\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "# Colab 의 한글 폰트 설정\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "# 유니코드에서  음수 부호설정\n",
        "mpl.rc('axes', unicode_minus=False)"
      ],
      "metadata": {
        "id": "ENvN_Qm9ZZtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import optuna\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import SuccessiveHalvingPruner\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "import xgboost as xgb\n"
      ],
      "metadata": {
        "id": "0TbQBBZuUBPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "kJ0WjRTVu7_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(path+\"train.csv\")\n",
        "test_df = pd.read_csv(path+\"test.csv\")\n",
        "submission = pd.read_csv(path+\"sample_submission.csv\")"
      ],
      "metadata": {
        "id": "gBH_vJcsUUDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " b= pd.read_csv(path+\"train.csv\")\n",
        " b.describe()"
      ],
      "metadata": {
        "id": "qfuqINBeeTjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.hist(bins=50, figsize=(10, 10))\n",
        "plt.show()\n",
        "corr_matrix = train_df.corr()\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(corr_matrix, annot=True, linewidth=1)"
      ],
      "metadata": {
        "id": "2GKpnTjpeNMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "주간통화시간+ 밤통화시간+저녁통화시간 , 3개 요금 합 , 저녁통화시간행 제거, (총 전화 시간)/총 횟수 ,"
      ],
      "metadata": {
        "id": "oD1hZNsBMu1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n"
      ],
      "metadata": {
        "id": "8EcWK7UvhxJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# autogluon 학습을 위한 데이터 형태로 변환\n",
        "train = TabularDataset(train_df.drop(['ID'], axis=1))\n",
        "test = TabularDataset(test_df.drop(['ID'], axis=1))\n"
      ],
      "metadata": {
        "id": "x-yC_-XUfZaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "predictor = TabularPredictor(label='전화해지여부', eval_metric='f1_macro',).fit(train)\n"
      ],
      "metadata": {
        "id": "9iCkMFWoh99d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# 각각의 모델의 훈련 성능을 평가할 수 있음\n",
        "ld_board = predictor.leaderboard(train, silent=True)\n",
        "\n",
        "ld_board\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "9JYNxnL0h-Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 좋은 성능인 모델 xgboost, xgboost 를 사용 하기로 결정\n"
      ],
      "metadata": {
        "id": "FcvEAjd3nszu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train= train.apply(lambda x: x.clip(x.quantile(.03), x.quantile(.97)), axis=0)\n"
      ],
      "metadata": {
        "id": "HuwcxEDGo1cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "hukFsvKPpC2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이상치가 있는 변수를 이상치 처리한다\n",
        "주성분\n",
        "전진\n",
        "후진\n",
        "단계적\n",
        "4가지의 데이터 셋을 각자 이상치 처리 데이터셋에 붙인후\n",
        "상위 모델인 xgboost, light 을 사용한다\n",
        "\n",
        "전진+(기본)주성분\n",
        "\n",
        "후진+(기본)주성분\n",
        "\n",
        "단계 +(기본)주성분\n",
        "\n",
        "기본+ (기본)주성분\n",
        "\n",
        "전진+전진(주성분)\n",
        "\n",
        "후진+후진(주성분)\n",
        "\n",
        "단계+단계(주성분)\n",
        "\n",
        "시간이 된다면 이상치 제거안한 데이터까지(시간이 없을듯...)"
      ],
      "metadata": {
        "id": "z9GZV7HJrcbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_df, y, test_size=0.2, random_state=156)\n"
      ],
      "metadata": {
        "id": "s2cXt1Dotnt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
        "    print('오차행렬 \\n', confusion_matrix(y_test, pred))\n",
        "    print('정확도 :', accuracy_score(y_test, pred))\n",
        "    print('정밀도 : ',precision_score(y_test, pred))\n",
        "    print('재현율 :', recall_score(y_test, pred))\n",
        "    print('f1 score :', f1_score(y_test, pred))\n",
        "    print('roc auc score :', roc_auc_score(y_test, pred_proba))\n",
        "\n",
        "def get_model_train_eval(model, ftr_train = None, ftr_test = None, tgt_train=None, tgt_test=None):\n",
        "    model.fit(ftr_train, tgt_train)\n",
        "    pred = model.predict(ftr_test)\n",
        "    pred_proba = model.predict_proba(ftr_test)[:,1]\n",
        "    get_clf_eval(tgt_test, pred, pred_proba)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def get_preprocessed_df(df=None):\n",
        "    df_copy = df.copy()\n",
        "    scaler = StandardScaler()\n",
        "    amount_n = scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
        "    df_copy.insert(0,'Amount_scaled', amount_n)\n",
        "    df_copy.drop(['Time','Amount'],axis=1, inplace=True)\n",
        "    return df_copy\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "h9-s2-EZvgkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "def evaluate_macroF1_lgb(y_true, y_pred):\n",
        "\n",
        "    y_pred_label = np.round(y_pred)\n",
        "\n",
        "    f1 = f1_score(y_true, y_pred_label, average='macro')\n",
        "\n",
        "    print('f1 score:', f1)\n",
        "\n",
        "    return ('f1_score', f1, True)\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "rVLK_1Nlv-FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "evals = [ (X_test, y_test) ]\n",
        "lgbm_wrapper = LGBMClassifier(n_estimators=4000)\n",
        "lgbm_wrapper.fit(X_train, y_train,\n",
        "                 # 조기 중단 파라미터\n",
        "                 early_stopping_rounds = 100, eval_metric = evaluate_macroF1_lgb, eval_set = evals,\n",
        "                 verbose=100)\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "hly9bXTFunVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "5gZJsgrhxsoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = train_df = pd.read_csv(path+\"train.csv\")\n",
        "df[df[\"전화해지여부\"]==1]\n",
        "df.head(30)"
      ],
      "metadata": {
        "id": "jWm9HBbWxAgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"전화해지여부\"]==1].head(30)\n"
      ],
      "metadata": {
        "id": "5_GyAhv1CpAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"전화해지여부\"]==1].count()"
      ],
      "metadata": {
        "id": "iHuX493oCsYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"전화해지여부\"]==1].hist(bins=50, figsize=(10, 10))\n",
        "plt.show()\n",
        "corr_matrix = df[df[\"전화해지여부\"]==1].corr()\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(corr_matrix, annot=True, linewidth=1)"
      ],
      "metadata": {
        "id": "wBby5zUwAch4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"전화해지여부\"]==0].hist(bins=50, figsize=(10, 10))\n",
        "plt.show()\n",
        "corr_matrix = df[df[\"전화해지여부\"]==0].corr()\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(corr_matrix, annot=True, linewidth=1)"
      ],
      "metadata": {
        "id": "rH7iswGYEMJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"전화해지여부\"]==1].hist(bins=50, figsize=(7, 7))\n",
        "plt.show()\n",
        "df[df[\"전화해지여부\"]==0].hist(bins=50, figsize=(7, 7))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tEsw8WGREhcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "G0ucLPxdEY9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uqatY0esxiw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "target = \"전화해지여부\"\n",
        "df = pd.read_csv(path + \"train.csv\")"
      ],
      "metadata": {
        "id": "dZ-NIpw3xyG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trains = []\n",
        "df_valids = []\n",
        "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
        "for train_index, valid_index in skf.split(df[features], df[target]):\n",
        "    df_train = df.loc[train_index]\n",
        "    df_valid = df.loc[valid_index]\n",
        "    df_trains.append(df_train)\n",
        "    df_valids.append(df_valid)\n",
        "def accuracy(true, pred):\n",
        "    return np.mean(true==pred)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 1024, step=1, log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 10, step=1, log=False),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.1, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 8, 1024, step=1, log=True),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50, step=1, log=False),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.7, 1.0),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
        "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 10.0),\n",
        "        'random_state': 0\n",
        "    }\n",
        "\n",
        "    score = []\n",
        "    for df_train, df_valid in zip(df_trains, df_valids):\n",
        "        clf = LGBMClassifier(**params)\n",
        "        clf.fit(df_train[features], df_train[target])\n",
        "\n",
        "        pred = clf.predict(df_valid[features])\n",
        "        true = df_valid[target].values\n",
        "        score.append(accuracy(true, pred))\n",
        "    score = np.mean(score)\n",
        "    return score\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=0), pruner=SuccessiveHalvingPruner())\n",
        "study.optimize(objective, n_trials=50)\n"
      ],
      "metadata": {
        "id": "DIIHpT2uvfs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(path+\"test.csv\")\n",
        "df_test\n",
        "df_te = df_test.drop([\"ID\"],axis = 1)\n",
        "df_tr = df_test = pd.read_csv(path+\"train.csv\")\n",
        "df = df_tr.drop([\"ID\",\"전화해지여부\"],axis = 1)\n",
        "df"
      ],
      "metadata": {
        "id": "Vk2-zOAa8zQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "id": "oCAuXq6w7Ozu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = []\n",
        "for df_train in df_trains:\n",
        "    clf = LGBMClassifier(**study.best_params)\n",
        "    clf.fit(df_train[features], df_train[target])\n",
        "    clfs.append(clf)\n",
        "\n",
        "# 테스트 데이터 불러오기\n",
        "df_test = pd.read_csv(path+\"test.csv\")\n",
        "df_test = df_test.drop([\"ID\"],axis =1)\n",
        "\n",
        "# 예측 수행 (soft voting)\n",
        "pred = [clf.predict_proba(df[features]) for clf in clfs]\n",
        "pred = np.mean(pred, axis=0)\n",
        "pred = np.argmax(pred, axis=1)"
      ],
      "metadata": {
        "id": "C73HJ6gtwP0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bK0wP6szzjKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "exXS85Eq7Mlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Cwm7noPZ8exN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "df_submission['전화해지여부'] = pred\n",
        "df_submission.to_csv('light_optuna.csv1', index=False)"
      ],
      "metadata": {
        "id": "hRGTQNFM9GlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission"
      ],
      "metadata": {
        "id": "gxy502AA9f4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 모델을 아무생각 없이 optuna 사용하니 0.7점 정도 나옴\n",
        "과적합이 크게 생기지 않으므로 과감한 전처리 보다 적당한 전처리를 하기로 결정\n"
      ],
      "metadata": {
        "id": "BfmzEvxr-nOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=df.drop([\"ID\",\"전화해지여부\"],axis=1).columns\n",
        "a"
      ],
      "metadata": {
        "id": "b9bGpNtOFqox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, ax = plt.subplots(1,12,figsize=(20,6))\n",
        "sns.boxplot(df['가입일'], ax=ax[0])\n",
        "sns.boxplot(df['음성사서함이용'], ax=ax[1])\n",
        "sns.boxplot(df['주간통화시간'], ax=ax[2])\n",
        "sns.boxplot(df['주간통화횟수'], ax=ax[3])\n",
        "sns.boxplot(df['주간통화요금'], ax=ax[4])\n",
        "sns.boxplot(df['저녁통화시간'], ax=ax[5])\n",
        "sns.boxplot(df['저녁통화횟수'], ax=ax[6])\n",
        "sns.boxplot(df['저녁통화요금'], ax=ax[7])\n",
        "sns.boxplot(df['밤통화시간'], ax=ax[8])\n",
        "sns.boxplot(df['밤통화횟수'], ax=ax[9])\n",
        "sns.boxplot(df['밤통화요금'], ax=ax[10])\n",
        "sns.boxplot(df['상담전화건수'], ax=ax[11])\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "4s-WUebnF1e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path+\"train.csv\")\n",
        "df_out = df[df['가입일']<480]\n",
        "df_out = df_out[df_out[\"음성사서함이용\"]<200]\n",
        "df_out"
      ],
      "metadata": {
        "id": "WcG7pWYGL13r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,4,figsize=(4, 4))\n",
        "sns.boxplot(df_out['가입일'], ax=ax[0])\n",
        "sns.boxplot(df_out['음성사서함이용'], ax=ax[1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZBkAQTE5K5p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OGn42_dJ7fiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5VPdrJNHLRb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr = df_out.drop([\"ID\",\"전화해지여부\"],axis =1 )\n",
        "df= df_tr\n",
        "y= df_out[\"전화해지여부\"]\n",
        "value = df_tr.columns\n",
        "\n",
        "value"
      ],
      "metadata": {
        "id": "F6pzaDwIGbaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#단계적 선택\n",
        "## 전진 단계별 선택법\n",
        "variables =  value## 설명 변수 리스트\n",
        "\n",
        "y ## 반응 변수\n",
        "selected_variables = [] ## 선택된 변수들\n",
        "sl_enter = 0.05\n",
        "sl_remove = 0.05\n",
        "\n",
        "sv_per_step = [] ## 각 스텝별로 선택된 변수들\n",
        "adjusted_r_squared = [] ## 각 스텝별 수정된 결정계수\n",
        "steps = [] ## 스텝\n",
        "step = 0\n",
        "while len(variables) > 0:\n",
        "    remainder = list(set(variables) - set(selected_variables))\n",
        "    pval = pd.Series(index=remainder) ## 변수의 p-value\n",
        "    ## 기존에 포함된 변수와 새로운 변수 하나씩 돌아가면서\n",
        "    ## 선형 모형을 적합한다.\n",
        "    for col in remainder:\n",
        "        X = df[selected_variables+[col]]\n",
        "        X = sm.add_constant(X)\n",
        "        model = sm.OLS(y,X).fit()\n",
        "        pval[col] = model.pvalues[col]\n",
        "\n",
        "    min_pval = pval.min()\n",
        "    if min_pval < sl_enter: ## 최소 p-value 값이 기준 값보다 작으면 포함\n",
        "        selected_variables.append(pval.idxmin())\n",
        "        ## 선택된 변수들에대해서\n",
        "        ## 어떤 변수를 제거할지 고른다.\n",
        "        while len(selected_variables) > 0:\n",
        "            selected_X = df[selected_variables]\n",
        "            selected_X = sm.add_constant(selected_X)\n",
        "            selected_pval = sm.OLS(y,selected_X).fit().pvalues[1:] ## 절편항의 p-value는 뺀다\n",
        "            max_pval = selected_pval.max()\n",
        "            if max_pval >= sl_remove: ## 최대 p-value값이 기준값보다 크거나 같으면 제외\n",
        "                remove_variable = selected_pval.idxmax()\n",
        "                selected_variables.remove(remove_variable)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        step += 1\n",
        "        steps.append(step)\n",
        "        adj_r_squared = sm.OLS(y,sm.add_constant(df[selected_variables])).fit().rsquared_adj\n",
        "        adjusted_r_squared.append(adj_r_squared)\n",
        "        sv_per_step.append(selected_variables.copy())\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "id": "OkgDgSIx7M1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_variables"
      ],
      "metadata": {
        "id": "CCGB8c_2-t_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "fig.set_facecolor('white')\n",
        "\n",
        "font_size = 15\n",
        "plt.xticks(steps,[f'step {s}\\n'+'\\n'.join(sv_per_step[i]) for i,s in enumerate(steps)], fontsize=12)\n",
        "plt.plot(steps,adjusted_r_squared, marker='o')\n",
        "\n",
        "plt.ylabel('Adjusted R Squared',fontsize=font_size)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QQmlBvlp-uuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA #여기붜 입력\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "jUcPVRXD-6_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr = pd.read_csv(path + \"train.csv\")\n",
        "tr = tr.drop([\"ID\"],axis =1 )\n",
        "tr=tr[tr['가입일']<480]\n",
        "tr = tr[tr[\"음성사서함이용\"]<200]\n",
        "y = tr[\"전화해지여부\"]\n",
        "tr = tr.drop([\"전화해지여부\"],axis =1 )\n",
        "tr.isnull().sum()"
      ],
      "metadata": {
        "id": "RT0Bw-E8E5MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr=tr.reset_index()\n"
      ],
      "metadata": {
        "id": "uQh9vfb6ZgER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr.isnull().sum()\n"
      ],
      "metadata": {
        "id": "HgiIqA44aI49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp =tr\n",
        "scaler = StandardScaler()\n",
        "temp = scaler.fit_transform(temp)\n",
        "temp"
      ],
      "metadata": {
        "id": "eT3qHu_2E-zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "pca.fit(temp)\n"
      ],
      "metadata": {
        "id": "DwG78PMoFRfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pca.explained_variance_)\n",
        "print(pca.explained_variance_ratio_)"
      ],
      "metadata": {
        "id": "4E_eKmg2FUge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum = 0\n",
        "for i, ratio in enumerate(pca.explained_variance_ratio_):\n",
        "    sum += ratio\n",
        "    print(f'{sum} by PCA{i}')"
      ],
      "metadata": {
        "id": "DR6sw4ArFWKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = pca.fit_transform(temp)\n",
        "temp = pd.DataFrame(temp)\n",
        "temp"
      ],
      "metadata": {
        "id": "odie6WR0FaWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr.isnull().sum()\n",
        "tr"
      ],
      "metadata": {
        "id": "yVcXZt45amFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.isnull().sum()"
      ],
      "metadata": {
        "id": "K5fKwwCLaoSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.concat([tr, temp.iloc[:, 0:9]], axis=1)\n"
      ],
      "metadata": {
        "id": "4Peg1bW7Fhdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train #중요 !! 전처리 완료\n",
        "df_train.isnull().sum()"
      ],
      "metadata": {
        "id": "Nxf-xStEFvO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score(true, pred):\n",
        "  from sklearn import metrics\n",
        "  from sklearn.metrics import accuracy_score, confusion_matrix # 평가 : 분류정확도\n",
        "  print('acc:', accuracy_score(true, pred))\n",
        "  print('\\nprecision:', metrics.precision_score(true, pred))\n",
        "  print('\\nrecall:', metrics.recall_score(true, pred))\n",
        "  print('\\nf1_score:', metrics.f1_score(true, pred))"
      ],
      "metadata": {
        "id": "DesVlPoAFxPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k =pd.read_csv(path+\"train.csv\")\n",
        "yk = k[\"전화해지여부\"]\n",
        "score(yk,pred)"
      ],
      "metadata": {
        "id": "vSP6MPLiIynQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_r =pd.read_csv(path + \"test.csv\")\n",
        "test_r = test_r.drop([\"ID\"],axis =1)"
      ],
      "metadata": {
        "id": "EuaRWvKIJa0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=y.reset_index()\n"
      ],
      "metadata": {
        "id": "F09mwF7KJebx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = y[\"전화해지여부\"]\n"
      ],
      "metadata": {
        "id": "JFDAg8YMb5NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "fcLVBrz9b9De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트 데이터 전처리\n"
      ],
      "metadata": {
        "id": "FGRFFJCZKiGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_te = test_r\n",
        "temp_te\n",
        "scaler = StandardScaler()\n",
        "temp_te = scaler.fit_transform(temp_te)\n",
        "temp_te"
      ],
      "metadata": {
        "id": "eFerXCcBKECf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "pca.fit(temp_te)"
      ],
      "metadata": {
        "id": "VRB9EX8SL2TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pca.explained_variance_)\n",
        "print(pca.explained_variance_ratio_)"
      ],
      "metadata": {
        "id": "q2mMCjGxL6Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum = 0\n",
        "for i, ratio in enumerate(pca.explained_variance_ratio_):\n",
        "    sum += ratio\n",
        "    print(f'{sum} by PCA{i}')"
      ],
      "metadata": {
        "id": "TPzdR0DKLt7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_te = pca.fit_transform(temp_te)\n",
        "temp_te = pd.DataFrame(temp_te)\n",
        "temp_te"
      ],
      "metadata": {
        "id": "RPdeYE4TL8_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.concat([test_r, temp_te.iloc[:, 0:9]], axis=1)\n",
        "df_test # 중요!! 전처리 완료\n",
        "df_test.isnull().sum()"
      ],
      "metadata": {
        "id": "wPkV3uqAKubl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train #중요 !! 전처리 완료 트레인셋\n",
        "y #중요 !! 트레인 y\n",
        "df_test # 중요!! 전처리 완료 테스트셋\n",
        "train = df_train\n",
        "test= df_test\n",
        "df_train"
      ],
      "metadata": {
        "id": "DMkmMrB5LmLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier as MLPC\n",
        "\n",
        "from xgboost import XGBClassifier as XGBC\n",
        "\n",
        "from lightgbm import LGBMClassifier as LGBMC\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "9hUcwOSr5TZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum()"
      ],
      "metadata": {
        "id": "5koRo6BmYP_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr = pd.read_csv(path + \"train.csv\")\n",
        "tr.info()"
      ],
      "metadata": {
        "id": "XNcZRA0J6bMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr.describe()"
      ],
      "metadata": {
        "id": "BdggjM1Q6fE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr = pd.read_csv(path + \"train.csv\")\n",
        "tr = tr.drop([\"ID\"],axis =1 )\n",
        "#tr=tr[tr['가입일']<400]\n",
        "#tr = tr[tr[\"음성사서함이용\"]<80]\n",
        "y = tr[\"전화해지여부\"]\n",
        "tr = tr.drop([\"전화해지여부\"],axis =1 )\n",
        "tr.isnull().sum()\n",
        "tr\n",
        "train = tr.reset_index()\n",
        "y = y.reset_index()\n",
        "y = y[\"전화해지여부\"]"
      ],
      "metadata": {
        "id": "WAH4GJX1wT9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.describe()"
      ],
      "metadata": {
        "id": "dZOxT20E66xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "주간통화시간+ 밤통화시간+저녁통화시간 , 3개 요금 합 , 저녁통화시간행 제거, (총 전화 시간)/총 횟수 ,\n",
        "['가입일', '음성사서함이용', '주간통화시간', '주간통화횟수', '주간통화요금', '저녁통화시간', '저녁통화횟수',\n",
        "       '저녁통화요금', '밤통화시간', '밤통화횟수', '밤통화요금', '상담전화건수'],"
      ],
      "metadata": {
        "id": "kqaNrDHaOcy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'a=pd.DataFrame()\n",
        "train['총전화시간'] = train['주간통화시간'] +train['저녁통화시간']+train['밤통화시간']\n",
        "train['총요금'] = train['주간통화요금'] + train['저녁통화요금'] +train['밤통화요금']\n",
        "#train['저녁1분평균'] = train['저녁통화시간']/train['저녁통화횟수']\n",
        "#train['밤1분평균'] = train['밤통화시간']/train['밤통화횟수']\n",
        "#train['주간1분평균'] = train['주간통화시간']/train['주간통화횟수']\n",
        "#train['시간당요금'] = train['총요금']/train['총전화시간']\n",
        "#train[\"총횟수\"] = train['주간통화횟수'] + train['저녁통화횟수'] +train['밤통화횟수']\n",
        "#train[\"1회당요금\"] =  train[총요금']/(train['주간통화횟수'] + train['저녁통화횟수'] +train['밤통화횟수'])\n",
        "#train['평균_상담'] = train['상담전화건수']/train['가입일']\n",
        "#train[\"주간횟수밤요금\"] = train[\"주간통화횟수\"]*train[\"밤통화요금\"]\n",
        "#train[\"밤시간요금\"] = train['밤통화시간']*train[\"밤통화요금\"]\n",
        "#train[\"주간밤요금시간\"] = train['주간통화요금']*train[\"밤통화시간\"]\n",
        "#train[\"주간밤시간요금\"] = train['주간통화시간']*train[\"밤통화요금\"]\n",
        "#train[\"주간저녁요금\"] = train['주간통화요금']*train[\"저녁통화요금\"]\n",
        "#train[\"주간저녁횟수\"] = train['주간통화시간']*train[\"저녁통화횟수\"]\n",
        "#train[\"주간밤시간\"] = train['주간통화시간']*train[\"밤통화시간\"]\n",
        "train = train.drop([\"index\"],axis =1 )\n",
        "\n"
      ],
      "metadata": {
        "id": "7zWEGqpYPhWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train  = train.drop(['가입일',\"음성사서함이용\"],axis = 1)"
      ],
      "metadata": {
        "id": "ct6zT4nvhtf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "khWBTKsB7Qrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=pd.read_csv(path + \"test.csv\")\n",
        "test = test.drop([\"ID\"],axis = 1)\n",
        "test = test.reset_index()\n",
        "test = test.iloc[:,1:]\n"
      ],
      "metadata": {
        "id": "0ve-QJuN3Scv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['총전화시간'] = test['주간통화시간'] +test['저녁통화시간']+test['밤통화시간']\n",
        "test[\"총요금\"] = test[\"주간통화요금\"] + test[\"밤통화요금\"] + test['저녁통화요금']\n",
        "\n",
        "#test['1회당_전화시간'] = test['총전화시간'] / test['총전화횟수']\n",
        "#test['1회당_전화요금'] = test['총전화시간'] *test[\"총요금\"]/ test['총전화횟수']\n",
        "#test['저녁1분평균'] = test['저녁통화시간']/test['저녁통화횟수']\n",
        "#test['밤1분평균'] = test['밤통화시간']/test['밤통화횟수']\n",
        "#test['시간당요금'] = test['총요금']/test['총전화시간']\n",
        "#test[\"총횟수\"] = test['주간통화횟수'] + test['저녁통화횟수'] +test['밤통화횟수']\n",
        "#test[\"1회당요금\"] =  test['총요금']/test['총횟수']\n",
        "#test['평균_상담'] = test['상담전화건수']/test['가입일']\n",
        "#test[\"주간횟수밤요금\"] = test[\"주간통화횟수\"]*test[\"밤통화요금\"]\n",
        "#test[\"밤시간요금\"] = test['밤통화시간']*test[\"밤통화요금\"]\n",
        "#test[\"주간밤요금시간\"] = test['주간통화요금']*test[\"밤통화시간\"]\n",
        "#test[\"주간밤시간요금\"] = test['주간통화시간']*test[\"밤통화요금\"]\n",
        "#test[\"주간저녁요금\"] = test['주간통화요금']*test[\"저녁통화요금\"]\n",
        "#test[\"주간저녁횟수\"] = test['주간통화시간']*test[\"저녁통화횟수\"]\n",
        "#test[\"주간밤시간\"] = test['주간통화시간']*test[\"밤통화시간\"]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v2864DjFSX1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test  = test.drop(['가입일',\"음성사서함이용\"],axis = 1)"
      ],
      "metadata": {
        "id": "AB9AGZqdiuQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "|test.info()"
      ],
      "metadata": {
        "id": "y1hOxQ7f70UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.replace([np.inf, -np.inf], 0)"
      ],
      "metadata": {
        "id": "TgeHrBKsgnmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jC5-jMvKgu5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_x = train\n",
        "raw_data_y =y"
      ],
      "metadata": {
        "id": "R9ebYIlq47U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_x"
      ],
      "metadata": {
        "id": "kPVGEeUJtn_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#case4\n",
        "train_x, test_x, train_y, test_y = train_test_split(raw_data_x, raw_data_y, test_size = 0.2,\n",
        "                                                    stratify = raw_data_y, random_state = 0)\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "train_x_sc_np = min_max_scaler.fit_transform(train_x)\n",
        "train_x_sc = pd.DataFrame(train_x_sc_np, columns=train_x.columns)\n",
        "\n",
        "test_x_sc_np = min_max_scaler.transform(test_x)\n",
        "test_x_sc = pd.DataFrame(test_x_sc_np, columns=test_x.columns)\n",
        "\n",
        "smoteto = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
        "x_tomek, y_tomek = smoteto.fit_resample(train_x_sc, train_y)\n",
        "\n",
        "lgbm = LGBMC(max_depth= 10, n_estimators= 700,\n",
        "             num_leaves= 1600, subsample= 0.8, random_state=0)\n",
        "lgbm.fit(x_tomek, y_tomek)\n",
        "\n",
        "train_pred = lgbm.predict(x_tomek)\n",
        "test_pred = lgbm.predict(test_x_sc)\n",
        "\n",
        "case_4 = metrics.f1_score(test_y, test_pred, average='macro')\n",
        "\n",
        "print(round(case_4, 4))"
      ],
      "metadata": {
        "id": "bMgqtExtdn6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#case4\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "train_x_sc_np = min_max_scaler.fit_transform(train)\n",
        "train_x_sc = pd.DataFrame(train_x_sc_np, columns=train.columns)\n",
        "\n",
        "test_x_sc_np = min_max_scaler.transform(test)\n",
        "test_x_sc = pd.DataFrame(test_x_sc_np, columns=test.columns)\n",
        "\n",
        "smoteto = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
        "x_tomek, y_tomek = smoteto.fit_resample(train_x_sc, y)\n"
      ],
      "metadata": {
        "id": "7wGN5FTZ9aVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = x_tomek\n",
        "y = y_tomek\n",
        "test = test_x_sc"
      ],
      "metadata": {
        "id": "gJ7_w9ZR9xp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = test_x_sc"
      ],
      "metadata": {
        "id": "QtPTUZCyofry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tomek.describe()"
      ],
      "metadata": {
        "id": "Vbqr1ZpbYAaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cu3NdPd9YBSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_trains = []\n",
        "df_valids = []\n",
        "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
        "for train_index, valid_index in skf.split(df[features], df[target]):\n",
        "    df_train = df.loc[train_index]\n",
        "    df_valid = df.loc[valid_index]\n",
        "    df_trains.append(df_train)\n",
        "    df_valids.append(df_valid)\n",
        "def accuracy(true, pred):\n",
        "    return np.mean(true==pred)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "             'max_depth': trial.suggest_int('max_depth', 2, 8, step=1, log=False),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 2500, step=1, log=True),\n",
        "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.01, 1.0),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0.01, 10.0),\n",
        "        'random_state': 123\n",
        "    }\n",
        "\n",
        "    score = []\n",
        "    for df_train, df_valid in zip(df_trains, df_valids):\n",
        "        clf = LGBMClassifier(**params)\n",
        "        clf.fit(df_train[features], df_train[target])\n",
        "        pred = clf.predict(df_valid[features])\n",
        "        true = df_valid[target].values\n",
        "        score.append(accuracy(true, pred))\n",
        "    score = np.mean(score)\n",
        "    return score\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=0), pruner=SuccessiveHalvingPruner())\n",
        "study.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "id": "9LNOPyh89olo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "GEBP4WV8Cusz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x_sc.info()"
      ],
      "metadata": {
        "id": "DcKp6p3YC00T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.info()"
      ],
      "metadata": {
        "id": "WA-UMaCnCYLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'max_depth': 8, 'learning_rate': 0.2899439078412818, 'n_estimators': 544, 'reg_alpha': 0.7327984691260165, 'reg_lambda': 2.651550167863645}\n",
        "\n",
        "'max_depth': 8, 'learning_rate': 0.22093511658561826, 'n_estimators': 863, 'reg_alpha': 0.5859320972852221, 'reg_lambda': 3.2068044359380448\n",
        "\n",
        "{'max_depth': 7, 'learning_rate': 0.22025231876663728, 'n_estimators': 1200, 'reg_alpha': 0.7460816001231388, 'reg_lambda': 3.340497200617224}\n",
        "\n",
        "'max_depth': 7, 'learning_rate': 0.22618277496802444, 'n_estimators': 1662, 'reg_alpha': 0.728749634526743, 'reg_lambda': 2.309661827978468"
      ],
      "metadata": {
        "id": "AQYaRlFb-yzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = []\n",
        "for df_train in df_trains:\n",
        "    clf = LGBMClassifier(**study.best_params)\n",
        "    clf.fit(df_train[features], df_train[target])\n",
        "    clfs.append(clf)\n",
        "\n",
        "# 테스트 데이터 불러오기\n",
        "df_test = test_x_sc\n",
        "\n",
        "# 예측 수행 (soft voting)\n",
        "pred = [clf.predict_proba(df_test[features]) for clf in clfs]\n",
        "pred = np.mean(pred, axis=0)\n",
        "pred = np.argmax(pred, axis=1)\n"
      ],
      "metadata": {
        "id": "htZR2uCo-C99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "df_submission['전화해지여부'] = pred\n",
        "df_submission.to_csv('light_optuna10.csv', index=False)"
      ],
      "metadata": {
        "id": "WQCExFpOC-Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "form google.colab import files\n",
        "files.download('light_optuna10.csv')"
      ],
      "metadata": {
        "id": "3OCcl9H6aou8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission.sum()"
      ],
      "metadata": {
        "id": "9o8PMqQwDS_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#case4\n",
        "train_x, test_x, train_y, test_y = train_test_split(raw_data_x, raw_data_y, test_size = 0.2,\n",
        "                                                    stratify = raw_data_y, random_state = 0)\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "train_x_sc_np = min_max_scaler.fit_transform(train)\n",
        "train_x_sc = pd.DataFrame(train_x_sc_np, columns=train.columns)\n",
        "\n",
        "test_x_sc_np = min_max_scaler.transform(test)\n",
        "test_x_sc = pd.DataFrame(test_x_sc_np, columns=test.columns)\n",
        "\n",
        "smoteto = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
        "x_tomek, y_tomek = smoteto.fit_resample(train_x_sc, y)\n",
        "\n"
      ],
      "metadata": {
        "id": "FUUb0ezG35rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hhYs3g7ydNn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rYBFEYSi6CLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "lgbm = LGBMC(max_depth= 10, n_estimators= 700,\n",
        "             num_leaves= 1600, subsample= 0.8, random_state=0)\n",
        "lgbm.fit(x_tomek, y_tomek)\n",
        "\n",
        "train_pred = lgbm.predict(x_tomek)\n",
        "test_pred = lgbm.predict(test_x_sc)\n",
        "\n",
        "case_4 = metrics.f1_score(test_y, test_pred, average='macro')\n",
        "\n",
        "print(round(case_4, 4))\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "yF1ZD17RSEyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tarin = x_tomek\n",
        "y= y_tomek\n",
        "test = test_x_sc"
      ],
      "metadata": {
        "id": "2qPP8KnKULPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = train.columns\n",
        "target = \"전화해지여부\"\n",
        "train_df= pd.concat([train, y], axis=1)\n",
        "\n",
        "features"
      ],
      "metadata": {
        "id": "KHlUKgIiSS09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = train.columns\n",
        "target = \"전화해지여부\"\n",
        "df= pd.concat([train, y], axis=1)\n",
        "\n",
        "features\n",
        "df_trains = []\n",
        "df_valids = []\n",
        "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
        "for train_index, valid_index in skf.split(df[features], df[target]):\n",
        "    df_train = df.loc[train_index]\n",
        "    df_valid = df.loc[valid_index]\n",
        "    df_trains.append(df_train)\n",
        "    df_valids.append(df_valid)\n",
        "def accuracy(true, pred):\n",
        "    return np.mean(true==pred)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 2, 8, step=1, log=False),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 2500, step=1, log=True),\n",
        "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.01, 1.0),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0.01, 10.0),\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    score = []\n",
        "    for df_train, df_valid in zip(df_trains, df_valids):\n",
        "        clf = LGBMClassifier(**params)\n",
        "        clf.fit(df_train[features], df_train[target])\n",
        "        pred = clf.predict(df_valid[features])\n",
        "        true = df_valid[target].values\n",
        "        score.append(accuracy(true, pred))\n",
        "    score = np.mean(score)\n",
        "    return score\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=0), pruner=SuccessiveHalvingPruner())\n",
        "study.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "id": "SEkletb45j5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = []\n",
        "for df_train in df_trains:\n",
        "    clf = LGBMClassifier(**study.best_params)\n",
        "    clf.fit(df_train[features], df_train[target])\n",
        "    clfs.append(clf)\n",
        "\n",
        "# 테스트 데이터 불러오기\n",
        "df_test = test\n",
        "\n",
        "\n",
        "# 예측 수행 (soft voting)\n",
        "pred = [clf.predict_proba(df_test[features]) for clf in clfs]\n",
        "pred = np.mean(pred, axis=0)\n",
        "pred = np.argmax(pred, axis=1)\n"
      ],
      "metadata": {
        "id": "IfKx2h3hTqYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "df_submission['전화해지여부'] = pred\n",
        "df_submission.to_csv('light_optuna6.csv', index=False)"
      ],
      "metadata": {
        "id": "I9BG0G0EZdnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trains = []\n",
        "df_valids = []\n",
        "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
        "for train_index, valid_index in skf.split(df[features], df[target]):\n",
        "    df_train = df.loc[train_index]\n",
        "    df_valid = df.loc[valid_index]\n",
        "    df_trains.append(df_train)\n",
        "    df_valids.append(df_valid)\n",
        "def accuracy(true, pred):\n",
        "    return np.mean(true==pred)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 2, 8, step=1, log=False),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 2500, step=1, log=True),\n",
        "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.01, 1.0),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0.01, 10.0),\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    score = []\n",
        "    for df_train, df_valid in zip(df_trains, df_valids):\n",
        "        clf = LGBMClassifier(**params)\n",
        "        clf.fit(df_train[features], df_train[target])\n",
        "        pred = clf.predict(df_valid[features])\n",
        "        true = df_valid[target].values\n",
        "        score.append(accuracy(true, pred))\n",
        "    score = np.mean(score)\n",
        "    return score\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=0), pruner=SuccessiveHalvingPruner())\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "clfs = []\n",
        "for df_train in df_trains:\n",
        "    clf = LGBMClassifier(**study.best_params)\n",
        "    clf.fit(df_train[features], df_train[target])\n",
        "    clfs.append(clf)\n",
        "\n",
        "# 테스트 데이터 불러오기\n",
        "df_test = test\n",
        "\n",
        "\n",
        "# 예측 수행 (soft voting)\n",
        "pred = [clf.predict_proba(df_test[features]) for clf in clfs]\n",
        "pred = np.mean(pred, axis=0)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "\n",
        "df_submission = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "df_submission['전화해지여부'] = pred\n",
        "df_submission.to_csv('light_optuna7.csv', index=False)"
      ],
      "metadata": {
        "id": "28Hi2nT7TZqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "URuCSKfvqZ_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "4zjak8G5rw5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "과적합 발생 주성분만 남기고 나머지 파생변수 추가해서 돌리던가\n",
        "횟수 빼고 파생변수와 기존 변수 돌리는게 제일 좋아 보임"
      ],
      "metadata": {
        "id": "Z1_cKywUEZAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = []\n",
        "for df_train in df_trains:\n",
        "    clf = LGBMClassifier(**study.best_params)\n",
        "    clf.fit(df_train[features], df_train[target])\n",
        "    clfs.append(clf)\n",
        "\n",
        "# 테스트 데이터 불러오기\n",
        "df_test = test\n",
        "\n",
        "\n",
        "# 예측 수행 (soft voting)\n",
        "pred = [clf.predict_proba(df_test[features]) for clf in clfs]\n",
        "pred = np.mean(pred, axis=0)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "\n",
        "df_submission = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "df_submission['전화해지여부'] = pred\n",
        "df_submission.to_csv('light_optuna7.csv', index=False)"
      ],
      "metadata": {
        "id": "2j5yo5n_TjBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "df_submission['전화해지여부'] = pred\n",
        "df_submission.to_csv('light_optuna5.csv', index=False)"
      ],
      "metadata": {
        "id": "mkCd1Y0zlb5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "시발왜 안됨"
      ],
      "metadata": {
        "id": "NarMpz8XD60L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ltR9eq0jHRnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "불균형 샘플링 사용 도전"
      ],
      "metadata": {
        "id": "mH12mTu8HTMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def y_label_count(df):\n",
        "    colors = ['lightsteelblue', '#FD9F31'] #'#0E1F55'\n",
        "\n",
        "    wedgeprops={'width': 0.7, 'edgecolor': 'k', 'linewidth': 0.75}\n",
        "\n",
        "    plt.subplots(figsize = (8,8))\n",
        "    plt.title('Ratio of Y_LABEL in Total Data', fontsize = 20, fontdict = {'weight': 'bold'})\n",
        "    plt.rc('font', size=12)\n",
        "    labels = ['0', '1']\n",
        "    plt.pie(df['전화해지여부'].value_counts(),\n",
        "            autopct=\"%.2f%%\", shadow = True, startangle = 90, textprops={'fontsize': 15},\n",
        "            colors = colors, wedgeprops = wedgeprops, labels = labels)"
      ],
      "metadata": {
        "id": "bH7fR7ABHVeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_un = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "raw_data = data_un\n",
        "y_label_count(raw_data)"
      ],
      "metadata": {
        "id": "Aa0cysdlHXHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_x = train\n",
        "raw_data_y = y"
      ],
      "metadata": {
        "id": "VrarSAt2H5Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.sum()"
      ],
      "metadata": {
        "id": "MJVPq62bdLO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier as MLPC\n",
        "\n",
        "from xgboost import XGBClassifier as XGBC\n",
        "\n",
        "from lightgbm import LGBMClassifier as LGBMC\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "CrsxegkPbUhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터가 상당히 불균형 함\n",
        "불균형한 데이터를 균형하게 샘플링 해주는 방법"
      ],
      "metadata": {
        "id": "FpMo2kf_Iniu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#case\n",
        "train_x, test_x, train_y, test_y = train_test_split(raw_data_x, raw_data_y, test_size = 0.2,\n",
        "                                                    stratify = raw_data_y, random_state = 0)\n",
        "\n",
        "lgbm = LGBMC(max_depth= 10, n_estimators= 700,\n",
        "             num_leaves= 1600, subsample= 0.8, random_state=0)\n",
        "lgbm.fit(train_x, train_y)\n",
        "\n",
        "train_pred = lgbm.predict(train_x)\n",
        "test_pred = lgbm.predict(test_x)\n",
        "\n",
        "case_1 = metrics.f1_score(test_y, test_pred, average='macro')\n",
        "print(round(case_1, 4))"
      ],
      "metadata": {
        "id": "FYTGbEAiIqE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#case2\n",
        "train_x, test_x, train_y, test_y = train_test_split(raw_data_x, raw_data_y, test_size = 0.2,\n",
        "                                                    stratify = raw_data_y, random_state = 0)\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "train_x_sc_np = min_max_scaler.fit_transform(train_x)\n",
        "train_x_sc = pd.DataFrame(train_x_sc_np, columns=train_x.columns)\n",
        "\n",
        "test_x_sc_np = min_max_scaler.transform(test_x)\n",
        "test_x_sc = pd.DataFrame(test_x_sc_np, columns=test_x.columns)\n",
        "\n",
        "lgbm = LGBMC(max_depth= 10, n_estimators= 700,\n",
        "             num_leaves= 1600, subsample= 0.8, random_state=0)\n",
        "lgbm.fit(train_x_sc, train_y)\n",
        "\n",
        "train_pred = lgbm.predict(train_x_sc)\n",
        "test_pred = lgbm.predict(test_x_sc)\n",
        "\n",
        "case_2 = metrics.f1_score(test_y, test_pred, average='macro')\n",
        "print(round(case_2, 4))"
      ],
      "metadata": {
        "id": "MN-NmiU8bT85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#case 3\n",
        "train_x, test_x, train_y, test_y = train_test_split(raw_data_x, raw_data_y, test_size = 0.2,\n",
        "                                                    stratify = raw_data_y, random_state = 0)\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "train_x_sc_np = min_max_scaler.fit_transform(train_x)\n",
        "train_x_sc = pd.DataFrame(train_x_sc_np, columns=train_x.columns)\n",
        "\n",
        "test_x_sc_np = min_max_scaler.transform(test_x)\n",
        "test_x_sc = pd.DataFrame(test_x_sc_np, columns=test_x.columns)\n",
        "\n",
        "x_smote, y_smote = SMOTE().fit_resample(train_x_sc, train_y)\n",
        "\n",
        "lgbm = LGBMC(max_depth= 10, n_estimators= 700,\n",
        "             num_leaves= 1600, subsample= 0.8, random_state=0)\n",
        "lgbm.fit(x_smote, y_smote)\n",
        "\n",
        "train_pred = lgbm.predict(x_smote)\n",
        "test_pred = lgbm.predict(test_x_sc)\n",
        "\n",
        "case_3 = metrics.f1_score(test_y, test_pred, average='macro')\n",
        "\n",
        "print(round(case_3, 4))"
      ],
      "metadata": {
        "id": "NAjvpg-LbjHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#case4\n",
        "train_x, test_x, train_y, test_y = train_test_split(raw_data_x, raw_data_y, test_size = 0.2,\n",
        "                                                    stratify = raw_data_y, random_state = 0)\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "train_x_sc_np = min_max_scaler.fit_transform(train_x)\n",
        "train_x_sc = pd.DataFrame(train_x_sc_np, columns=train_x.columns)\n",
        "\n",
        "test_x_sc_np = min_max_scaler.transform(test_x)\n",
        "test_x_sc = pd.DataFrame(test_x_sc_np, columns=test_x.columns)\n",
        "\n",
        "smoteto = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
        "x_tomek, y_tomek = smoteto.fit_resample(train_x_sc, train_y)\n",
        "\n",
        "lgbm = LGBMC(max_depth= 10, n_estimators= 700,\n",
        "             num_leaves= 1600, subsample= 0.8, random_state=0)\n",
        "lgbm.fit(x_tomek, y_tomek)\n",
        "\n",
        "train_pred = lgbm.predict(x_tomek)\n",
        "test_pred = lgbm.predict(test_x_sc)\n",
        "\n",
        "case_4 = metrics.f1_score(test_y, test_pred, average='macro')\n",
        "\n",
        "print(round(case_4, 4))"
      ],
      "metadata": {
        "id": "jlxrFYh-cEm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tomek"
      ],
      "metadata": {
        "id": "ROoLodsEdxX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#case5\n",
        "train_x, test_x, train_y, test_y = train_test_split(raw_data_x, raw_data_y, test_size = 0.2,\n",
        "                                                    stratify = raw_data_y, random_state = 0)\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "train_x_sc_np = min_max_scaler.fit_transform(train_x)\n",
        "train_x_sc = pd.DataFrame(train_x_sc_np, columns=train_x.columns)\n",
        "\n",
        "test_x_sc_np = min_max_scaler.transform(test_x)\n",
        "test_x_sc = pd.DataFrame(test_x_sc_np, columns=test_x.columns)\n",
        "\n",
        "adasyn = ADASYN(random_state=0)\n",
        "x_adasyn, y_adasyn = adasyn.fit_resample(train_x_sc, train_y)\n",
        "\n",
        "lgbm = LGBMC(max_depth= 10, n_estimators= 700,\n",
        "             num_leaves= 1600, subsample= 0.8, random_state=0)\n",
        "lgbm.fit(x_adasyn, y_adasyn)\n",
        "\n",
        "train_pred = lgbm.predict(x_adasyn)\n",
        "test_pred = lgbm.predict(test_x_sc)\n",
        "\n",
        "case_5 = metrics.f1_score(test_y, test_pred, average='macro')\n",
        "print(round(case_5, 4))"
      ],
      "metadata": {
        "id": "wCWTG04_bofg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install eli5\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "ISptCGJWZdir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import platform\n",
        "import random\n",
        "import math\n",
        "from typing import List ,Dict, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import catboost\n",
        "import eli5\n",
        "import optuna\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedKFold , KFold\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from catboost import Pool,CatBoostClassifier"
      ],
      "metadata": {
        "id": "h2FocLStZV5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr = pd.read_csv(path + \"train.csv\")\n",
        "tr = tr.drop([\"ID\"],axis =1 )\n",
        "tr=tr[tr['가입일']<480]\n",
        "tr = tr[tr[\"음성사서함이용\"]<200]\n",
        "y = tr[\"전화해지여부\"]\n",
        "tr = tr.drop([\"전화해지여부\"],axis =1 )\n",
        "tr.isnull().sum()\n",
        "tr\n",
        "train = tr.reset_index()\n",
        "y = y.reset_index()\n",
        "y = y[\"전화해지여부\"]"
      ],
      "metadata": {
        "id": "d7_6k6O2Y3ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=pd.read_csv(path + \"test.csv\")\n",
        "test = test.drop([\"ID\"],axis = 1)\n",
        "test = test.reset_index()\n",
        "test = test.iloc[:,1:]\n"
      ],
      "metadata": {
        "id": "gZQaMo0NZLj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(train, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "TbJr7K3Xd4LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "model=CatBoostClassifier(silent=True, random_state=0).fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "0pkIJVAxZW8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perm = PermutationImportance(model, random_state=3).fit(x_valid, y_valid)\n",
        "eli5.show_weights(perm, feature_names = x_valid.columns.tolist(), top=100)"
      ],
      "metadata": {
        "id": "EdF9jHEyZvX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " OPTUNA_OPTIMIZATION = True\n",
        "\n",
        " def objective(trial):\n",
        "     train_x, valid_x, train_y, valid_y = train_test_split(train,y_train, test_size=0.3)\n",
        "\n",
        "     #define parameters\n",
        "     params = {\n",
        "         'iterations':trial.suggest_int(\"iterations\", 500, 3000),\n",
        "         'objective':trial.suggest_categorical('objective',['CrossEntropy','Logloss']),\n",
        "         'bootstrap_type':trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
        "         'od_wait':trial.suggest_int('od_wait', 500, 1000),\n",
        "         'learning_rate' : trial.suggest_uniform('learning_rate',0.01,1),\n",
        "         'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
        "         'random_strength': trial.suggest_uniform('random_strength',20,50),\n",
        "         'depth': trial.suggest_int('depth',1,15),\n",
        "         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,20),\n",
        "         'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
        "         'verbose': False,\n",
        "         \"eval_metric\":'F1',\n",
        "         \"one_hot_max_size\":trial.suggest_int(\"one_hot_max_size\",1,5),\n",
        "         'task_type' : 'GPU',\n",
        "     }\n",
        "\n",
        "     if params['bootstrap_type'] == 'Bayesian':\n",
        "         params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
        "     elif params['bootstrap_type'] == 'Bernoulli':\n",
        "         params['subsample'] = trial.suggest_float('subsample', 0.1, 1)\n",
        "\n",
        "     # model fit\n",
        "     model = CatBoostClassifier(**params)\n",
        "     model.fit(\n",
        "         train_x, train_y, eval_set=[(valid_x, valid_y)],\n",
        "         use_best_model=True\n",
        "     )\n",
        "\n",
        "  # validation prediction\n",
        "     preds = model.predict(valid_x)\n",
        "     pred_labels = np.rint(preds)\n",
        "     score = f1_score(valid_y, pred_labels)\n",
        "     return score"
      ],
      "metadata": {
        "id": "ZHntNnLkaU34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " study = optuna.create_study(\n",
        "     direction='maximize',\n",
        "     study_name='CatbClf'\n",
        " )\n",
        "\n",
        " study.optimize( objective,n_trials=50)"
      ],
      "metadata": {
        "id": "v7n68-62aU7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = train.columns\n",
        "target = \"전화해지여부\"\n",
        "df= pd.concat([train, y], axis=1)"
      ],
      "metadata": {
        "id": "dBSLuwdeUIqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = train.columns\n",
        "target = \"전화해지여부\"\n",
        "df= pd.concat([train, y], axis=1)\n",
        "\n",
        "features\n",
        "df_trains = []\n",
        "df_valids = []\n",
        "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
        "for train_index, valid_index in skf.split(df[features], df[target]):\n",
        "    df_train = df.loc[train_index]\n",
        "    df_valid = df.loc[valid_index]\n",
        "    df_trains.append(df_train)\n",
        "    df_valids.append(df_valid)\n",
        "def accuracy(true, pred):\n",
        "    return np.mean(true==pred)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 2, 8, step=1, log=False),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 2500, step=1, log=True),\n",
        "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.01, 1.0),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0.01, 10.0),\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    score = []\n",
        "    for df_train, df_valid in zip(df_trains, df_valids):\n",
        "        clf = LGBMClassifier(**params)\n",
        "        clf.fit(df_train[features], df_train[target])\n",
        "        pred = clf.predict(df_valid[features])\n",
        "        true = df_valid[target].values\n",
        "        score.append(accuracy(true, pred))\n",
        "    score = np.mean(score)\n",
        "    return score\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=0), pruner=SuccessiveHalvingPruner())\n",
        "study.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "id": "lT5YCCzPjo0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = []\n",
        "for df_train in df_trains:\n",
        "    clf = LGBMClassifier(**study.best_params)\n",
        "    clf.fit(df_train[features], df_train[target])\n",
        "    clfs.append(clf)\n",
        "\n",
        "# 테스트 데이터 불러오기\n",
        "df_test = test\n",
        "\n",
        "\n",
        "# 예측 수행 (soft voting)\n",
        "pred = [clf.predict_proba(df_test[features]) for clf in clfs]\n",
        "pred = np.mean(pred, axis=0)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "\n",
        "df_submission = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "df_submission['전화해지여부'] = pred\n",
        "df_submission.to_csv('light_optuna7.csv', index=False)"
      ],
      "metadata": {
        "id": "nARSk5F4kqom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-p87H0ks-Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "값이 제일 좋은\n",
        "min-max scaler 후 smote-tomek 샘플링이 가장 큰 스코아값\n",
        "이상치의 민감함으로 이상치를 제거 하여 다시 샘플링 한다"
      ],
      "metadata": {
        "id": "joEu0rkxeE3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "smote - tomek 기법에 optuna 사용 하여 모델링 구축한후 점수를 본다"
      ],
      "metadata": {
        "id": "R1JD3GHoeeUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "주성분 분석은 크게 도움이 되지 않는걸 확인\n",
        "상관 계수가 현저히 낮은 것 제거와 파생변수 생성 한후 제출\n"
      ],
      "metadata": {
        "id": "pvnr0_TsvtrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # 선형 대수\n",
        "import pandas as pd # 데이터 처리\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk(''):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "1nLdxEbgs_CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt # 시각화\n",
        "import seaborn as sns # 시각화\n",
        "\n",
        "import warnings # 경고 메시지 무시\n",
        "warnings.filterwarnings('ignore') # 경고 메시지 무시\n",
        "train = pd.read_csv(path+'train.csv')\n",
        "test = pd.read_csv(path+'test.csv')\n",
        "df_val = pd.read_csv(path+'sample_submission.csv')\n",
        "\n",
        "a=pd.DataFrame()\n",
        "train['총전화시간'] = train['주간통화시간'] +train['저녁통화시간']+train['밤통화시간']\n",
        "train['총요금'] = train['주간통화요금'] + train['저녁통화요금'] +train['밤통화요금']\n",
        "# train['저녁1분평균'] = train['저녁통화시간']/train['저녁통화횟수']\n",
        "# train['밤1분평균'] = train['밤통화시간']/train['밤통화횟수']\n",
        "#train['시간당요금'] = train['총요금']/train['총전화시간']\n",
        "train[\"총횟수\"] = train['주간통화횟수'] + train['저녁통화횟수'] +train['밤통화횟수']\n",
        "train['평균_상담'] = train['상담전화건수']/train['가입일']\n",
        "#train[\"주간상담\"]= train[\"주간통화요금\"]*train['저녁통화시간']\n",
        "#train[\"주간횟수밤요금\"] = train[\"주간통화횟수\"]*train[\"밤통화요금\"]\n",
        "test['총전화시간'] = test['주간통화시간'] +test['저녁통화시간']+test['밤통화시간']\n",
        "test[\"총요금\"] = test[\"주간통화요금\"] + test[\"밤통화요금\"] + test['저녁통화요금']\n",
        "\n",
        "#test['1회당_전화시간'] = test['총전화시간'] / test['총전화횟수']\n",
        "#test['1회당_전화요금'] = test['총전화시간'] *test[\"총요금\"]/ test['총전화횟수']\n",
        "#test['저녁1분평균'] = test['저녁통화시간']/test['저녁통화횟수']\n",
        "#test['밤1분평균'] = test['밤통화시간']/test['밤통화횟수']\n",
        "test[\"총횟수\"] = test['주간통화횟수'] + test['저녁통화횟수'] +test['밤통화횟수']\n",
        "test['평균_상담'] = test['상담전화건수']/test['가입일']\n",
        "df_test= test\n",
        "df_train = train"
      ],
      "metadata": {
        "id": "HrLRoYBBtALL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "id": "Zgt-lv3uukEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['전화해지여부'] = df_val['전화해지여부']"
      ],
      "metadata": {
        "id": "tZ1BZIIztOzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_train.drop(['전화해지여부','ID'],axis=1) # 데이터 분리\n",
        "\n",
        "y = df_train['전화해지여부'] # 데이터 분리\n",
        "\n",
        "y.head()"
      ],
      "metadata": {
        "id": "sNF0abfmtO_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8,test_size=0.2,random_state=100) # 데이터 분리\n"
      ],
      "metadata": {
        "id": "Ga8kHXlJuACl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial()) # 로지스틱 회귀 모델 생성\n",
        "logm1.fit().summary() # 모델 요약"
      ],
      "metadata": {
        "id": "wFRzqPHTuBy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = X_test.drop(['저녁통화횟수',\"저녁통화요금\",\"밤통화횟수\"],1) # 불필요한 데이터 삭제\n",
        "X_train2 = X_train.drop(['저녁통화횟수',\"저녁통화요금\",\"밤통화횟수\"],1) # 불필요한 데이터 삭제"
      ],
      "metadata": {
        "id": "WmHv5IvtuIsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20,10))\n",
        "sns.heatmap(X_train2.corr(),annot = True) # 상관관계 히트맵 확인"
      ],
      "metadata": {
        "id": "ISW5Gb8gu2qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "logm2 = sm.GLM(y_train,(sm.add_constant(X_train2)), family = sm.families.Binomial()) # 로지스틱 회귀 모델 생성\n",
        "logm2.fit().summary()"
      ],
      "metadata": {
        "id": "Lo2ClDf4u-DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "from sklearn.feature_selection import RFE\n",
        "rfe = RFE(logreg) # 변수 선택\n",
        "rfe = rfe.fit(X,y)  # 변수 선택\n",
        "print(rfe.support_) # 변수 선택 확인\n",
        "print(rfe.ranking_) # 변수 선택 확인"
      ],
      "metadata": {
        "id": "sPIEoV_avBI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col = [\"가입일\",\"음성사서함이용\",\"주간통화시간\",\"밤통화요금\",\"상담전화건수\"]"
      ],
      "metadata": {
        "id": "RdFX1G2JvkaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "logsk = LogisticRegression(C=1e9) # 로지스틱 회귀 모델 생성\n",
        "logsk.fit(X_train, y_train) # 모델 생성"
      ],
      "metadata": {
        "id": "hfmRyBe_vtHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logm4 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial()) # 로지스틱 회귀 모델 생성\n",
        "modres = logm4.fit() # 모델 생성\n",
        "logm4.fit().summary()"
      ],
      "metadata": {
        "id": "bLJTv060vu6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[col].shape"
      ],
      "metadata": {
        "id": "Iqj5InX7vwgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = logsk.predict_proba(X_test) # 예측\n",
        "y_pred_df = pd.DataFrame(y_pred)\n",
        "y_pred_1 = y_pred_df.iloc[:,[1]]\n",
        "y_pred_1"
      ],
      "metadata": {
        "id": "XrHa3NAyvySj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_test_df = pd.DataFrame(y_test)\n",
        "y_test_df"
      ],
      "metadata": {
        "id": "ehbyPOAkvzvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_df['ID'] = y_test_df.index # 데이터 합치기\n",
        "y_pred_1.reset_index(drop=True, inplace=True) # 데이터 합치기\n",
        "y_test_df.reset_index(drop=True, inplace=True) # 데이터 합치기\n",
        "y_pred_final = pd.concat([y_test_df,y_pred_1],axis=1) # 데이터 합치기\n",
        "y_pred_final= y_pred_final.rename(columns={ 1 : '전화해지여부_Prob'}) # 데이터 합치기\n",
        "y_pred_final = y_pred_final.reindex(['ID','전화해지여부','전화해지여부_Prob'], axis=1) # 데이터 합치기\n",
        "y_pred_final.head()"
      ],
      "metadata": {
        "id": "gdcG3MBZwA2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_final['predicted'] = y_pred_final.전화해지여부_Prob.map( lambda x: 1 if x > 0.5 else 0) # 예측값 생성\n",
        "\n",
        "y_pred_final.head()"
      ],
      "metadata": {
        "id": "VbsLdTO2v1UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n"
      ],
      "metadata": {
        "id": "Jc9ArZv4v3ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion = metrics.confusion_matrix( y_pred_final.전화해지여부, y_pred_final.predicted ) # 혼동행렬 생성\n",
        "confusion"
      ],
      "metadata": {
        "id": "bMMvGlz_wT7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.accuracy_score(y_pred_final.전화해지여부, y_pred_final.predicted) # 정확도 확인\n"
      ],
      "metadata": {
        "id": "mo5ClD8-wVS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(random_state=42) # PCA 생성\n",
        "pca.fit(X_train) # PCA 생성\n",
        "pca.components_ # PCA 생성\n",
        "pca.explained_variance_ratio_ # PCA 생성\n",
        "var_cumu = np.cumsum(pca.explained_variance_ratio_) # PCA 생성\n"
      ],
      "metadata": {
        "id": "Epgay1XGwY2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=[12,8])\n",
        "plt.vlines(x=2.5, ymax=1, ymin=0, colors=\"r\", linestyles=\"--\")\n",
        "plt.hlines(y=0.8, xmax=15, xmin=0, colors=\"g\", linestyles=\"--\")\n",
        "plt.plot(var_cumu)\n",
        "plt.ylabel(\"Cumulative variance explained\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zzXLC41JwhXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TNY1QsVwwssz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n"
      ],
      "metadata": {
        "id": "KtWN2vOYwqRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_final = IncrementalPCA(n_components=3) # PCA 생성\n"
      ],
      "metadata": {
        "id": "m3Prv4Mewl1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_pca = pca_final.fit_transform(X_train) # PCA 생성\n"
      ],
      "metadata": {
        "id": "eoWpPiTCwpGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corrmat = np.corrcoef(df_train_pca.transpose()) # PCA 생성\n"
      ],
      "metadata": {
        "id": "pF0XaQqswuUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_pca = pca_final.transform(X_test) # PCA 생성\n"
      ],
      "metadata": {
        "id": "eOCUYb9Vwvpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "metadata": {
        "id": "P5G0A1HGwwf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner_pca = LogisticRegression() # 로지스틱 회귀 모델 생성\n"
      ],
      "metadata": {
        "id": "YAkqHwNywxYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pca = learner_pca.fit(df_train_pca, y_train) # 로지스틱 회귀 모델 생성\n"
      ],
      "metadata": {
        "id": "PblFcXuTwyCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs_test = model_pca.predict_proba(df_test_pca) # 예측\n"
      ],
      "metadata": {
        "id": "W83aD6EHwytR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_again = PCA(0.9) # PCA 생성\n"
      ],
      "metadata": {
        "id": "atGZ1BRYwz1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_pca2 = pca_again.fit_transform(X_train) # PCA 생성\n"
      ],
      "metadata": {
        "id": "TJcvbUYGw0W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "learner_pca2 = LogisticRegression() # 로지스틱 회귀 모델 생성\n"
      ],
      "metadata": {
        "id": "0zI8PteOw1tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner_pca2 = LogisticRegression() # 로지스틱 회귀 모델 생성\n"
      ],
      "metadata": {
        "id": "ezokI5Zfw2pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pca2 = learner_pca2.fit(df_train_pca2, y_train) # 로지스틱 회귀 모델 생성\n"
      ],
      "metadata": {
        "id": "XPPYBbblw3ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca1 =model_pca.predict(df_test_pca)\n"
      ],
      "metadata": {
        "id": "8cssqzNOw4Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "cnt = Counter(pca1)\n",
        "cnt"
      ],
      "metadata": {
        "id": "CahDTIP0piJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs_test2 = model_pca2.predict_proba(df_test_pca2)[:,1] # 예측\n",
        "pred_probs_test2\n",
        "y_pred_final['predicted'] = y_pred_final.전화해지여부_Prob.map( lambda x: 1 if x > 0.5 else 0) # 예측값 생성\n",
        "\n",
        "y_pred_final.head()"
      ],
      "metadata": {
        "id": "KWh3dhcTw5VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test =df_test\n",
        "print(y_test)"
      ],
      "metadata": {
        "id": "ZNeUnlcYw8th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_with_labels"
      ],
      "metadata": {
        "id": "GdeavAanw-de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import warnings\n",
        "import io\n",
        "import requests\n",
        "\n",
        "url=\"https://github.com/thisisjasonjafari/my-datascientise-handcode/raw/master/005-datavisualization/titanic.csv\" # 데이터 불러오기\n",
        "s=requests.get(url).content # 데이터 불러오기\n",
        "c=pd.read_csv(io.StringIO(s.decode('utf-8'))) # 데이터 불러오기\n",
        "\n",
        "test_data_with_labels = c # 데이터 불러오기"
      ],
      "metadata": {
        "id": "ocOXmtMGxLMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, name in enumerate(['name']): # 이름에서 호칭 추출\n",
        "    if '\"' in name:\n",
        "        test_data_with_labels['name'][i] = re.sub('\"', '', name)\n",
        "\n",
        "for i, name in enumerate(df_test['Name']): # 이름에서 호칭 추출\n",
        "    if '\"' in name:\n",
        "        df_test['Name'][i] = re.sub('\"', '', name)\n",
        "\n",
        "survived = []\n",
        "\n",
        "for name in df_test['Name']: # 이름에서 호칭 추출\n",
        "    survived.append(int(test_data_with_labels.loc[test_data_with_labels['name'] == name]['전화해지여부'].values[-1]))"
      ],
      "metadata": {
        "id": "5felp6FRxORI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(train.shape[1]):\n",
        "    sns.distplot(train[i])\n",
        "    plt.title(feature_names[i])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oKvLDOWuxRxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt # 시각화\n",
        "import seaborn as sns # 시각화\n",
        "\n",
        "import warnings # 경고 메시지 무시\n",
        "warnings.filterwarnings('ignore') # 경고 메시지 무시\n",
        "train = pd.read_csv(path+'train.csv')\n",
        "test = pd.read_csv(path+'test.csv')\n",
        "df_val = pd.read_csv(path+'sample_submission.csv')\n",
        "\n",
        "a=pd.DataFrame()\n",
        "train['총전화시간'] = train['주간통화시간'] +train['저녁통화시간']+train['밤통화시간']\n",
        "train['총요금'] = train['주간통화요금'] + train['저녁통화요금'] +train['밤통화요금']\n",
        "# train['저녁1분평균'] = train['저녁통화시간']/train['저녁통화횟수']\n",
        "# train['밤1분평균'] = train['밤통화시간']/train['밤통화횟수']\n",
        "train['시간당요금'] = train['총요금']/train['총전화시간']\n",
        "train[\"총횟수\"] = train['주간통화횟수'] + train['저녁통화횟수'] +train['밤통화횟수']\n",
        "train['평균_상담'] = train['상담전화건수']/train['가입일']\n",
        "#train[\"주간상담\"]= train[\"주간통화요금\"]*train['저녁통화시간']\n",
        "#train[\"주간횟수밤요금\"] = train[\"주간통화횟수\"]*train[\"밤통화요금\"]\n",
        "\n",
        "test['총전화시간'] = test['주간통화시간'] +test['저녁통화시간']+test['밤통화시간']\n",
        "test[\"총요금\"] = test[\"주간통화요금\"] + test[\"밤통화요금\"] + test['저녁통화요금']\n",
        "\n",
        "#test['1회당_전화시간'] = test['총전화시간'] / test['총전화횟수']\n",
        "#test['1회당_전화요금'] = test['총전화시간'] *test[\"총요금\"]/ test['총전화횟수']\n",
        "#test['저녁1분평균'] = test['저녁통화시간']/test['저녁통화횟수']\n",
        "#test['밤1분평균'] = test['밤통화시간']/test['밤통화횟수']\n",
        "test['시간당요금'] = test['총요금']/test['총전화시간']\n",
        "test[\"총횟수\"] = test['주간통화횟수'] + test['저녁통화횟수'] +test['밤통화횟수']\n",
        "test['평균_상담'] = test['상담전화건수']/test['가입일']\n",
        "df_test= test\n",
        "df_train = train"
      ],
      "metadata": {
        "id": "iU2dIbASyYQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "uhCWrmY6qDcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp= train"
      ],
      "metadata": {
        "id": "JnNoOmLTqhUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "temp = scaler.fit_transform(temp)\n",
        "temp"
      ],
      "metadata": {
        "id": "yvkuF5LuqE-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_train = PCA()\n",
        "pca_train.fit(temp)"
      ],
      "metadata": {
        "id": "CToOQVw-qoYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pca_train.explained_variance_)\n",
        "print(pca_train.explained_variance_ratio_)"
      ],
      "metadata": {
        "id": "WntNZmuqqq0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum = 0\n",
        "for i, ratio in enumerate(pca_train.explained_variance_ratio_):\n",
        "    sum += ratio\n",
        "    print(f'{sum} by PCA{i}')"
      ],
      "metadata": {
        "id": "yUvCKhZkqsG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8번까지 사용용"
      ],
      "metadata": {
        "id": "Muf-p9rAqun6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_test= test.drop([\"ID\"],axis =1)"
      ],
      "metadata": {
        "id": "fPvb91Y2qwKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "temp_test = scaler.fit_transform(temp_test)\n"
      ],
      "metadata": {
        "id": "3O3l5LDFrB6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_test = PCA()\n",
        "pca_test.fit(temp_test)"
      ],
      "metadata": {
        "id": "5nD5-rHrrV6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum = 0\n",
        "for i, ratio in enumerate(pca_test.explained_variance_ratio_):\n",
        "    sum += ratio\n",
        "    print(f'{sum} by PCA{i}')"
      ],
      "metadata": {
        "id": "ezaiAXZqrIPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8번까지 씀"
      ],
      "metadata": {
        "id": "aHxBvORR2DFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_train = pca_train.fit_transform(temp)\n",
        "temp_train = pd.DataFrame(temp)\n",
        "temp_train"
      ],
      "metadata": {
        "id": "iwowz_41rn12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_test = pca_train.fit_transform(temp_test)\n",
        "temp_test = pd.DataFrame(temp_test)\n",
        "temp_test"
      ],
      "metadata": {
        "id": "yx0DIEWL2-Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "yuICFOjV4_fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(path+'train.csv')"
      ],
      "metadata": {
        "id": "k3M4rUbV4mUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=train_df['전화해지여부']"
      ],
      "metadata": {
        "id": "sOgaKzbM5X4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = temp_train.iloc[:,0:9]\n",
        "test = temp_test.iloc[:,0:9]"
      ],
      "metadata": {
        "id": "5dEWTHLH5cso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "J_kI645dXWFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FneIxfoyXi2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = train.columns\n",
        "target = \"전화해지여부\"\n",
        "df= pd.concat([train, y], axis=1)\n",
        "\n",
        "df_trains = []\n",
        "df_valids = []\n",
        "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
        "for train_index, valid_index in skf.split(df[features], df[target]):\n",
        "    df_train = df.loc[train_index]\n",
        "    df_valid = df.loc[valid_index]\n",
        "    df_trains.append(df_train)\n",
        "    df_valids.append(df_valid)\n",
        "def accuracy(true, pred):\n",
        "    return np.mean(true==pred)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 2, 10, step=1, log=False),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
        "\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    score = []\n",
        "    for df_train, df_valid in zip(df_trains, df_valids):\n",
        "        clf = LGBMClassifier(**params)\n",
        "        clf.fit(df_train[features], df_train[target])\n",
        "        pred = clf.predict(df_valid[features])\n",
        "        true = df_valid[target].values\n",
        "        score.append(accuracy(true, pred))\n",
        "    score = np.mean(score)\n",
        "    return score\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=0), pruner=SuccessiveHalvingPruner())\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JCBoo1pv8Xsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "랜덤 서치, 옵튜나, 그리드 서치\n",
        "랜덤서치 빠륵다  - 단점"
      ],
      "metadata": {
        "id": "z3HU1_Dgsc7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "6ryufPFBsdBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.sum()"
      ],
      "metadata": {
        "id": "QUpVVGHuF-IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "NQdsgzJgsdGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = []\n",
        "for df_train in df_trains:\n",
        "    clf = LGBMClassifier(**study.best_params)\n",
        "    clf.fit(df_train[features], df_train[target])\n",
        "    clfs.append(clf)\n",
        "\n",
        "# 테스트 데이터 불러오기\n",
        "df_test = test\n",
        "\n",
        "\n",
        "# 예측 수행 (soft voting)\n",
        "pred = [clf.predict_proba(df_test[features]) for clf in clfs]\n",
        "pred = np.mean(pred, axis=0)\n",
        "pred = np.argmax(pred, axis=1)\n"
      ],
      "metadata": {
        "id": "szZxKj45Cj4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "daq7__9TE3ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "QGg7DI6qo0ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df_submission = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "df_submission['전화해지여부'] = pred\n",
        "df_submission.to_csv('light_optuna15.csv',index=False)"
      ],
      "metadata": {
        "id": "5DLesWqt9exG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission.sum()"
      ],
      "metadata": {
        "id": "Y-s7X4YPE7HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "from contextlib import contextmanager\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from bayes_opt import BayesianOptimization\n",
        "# from skopt import BayesSearchCV\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# from yellowbrick.cluster import KElbowVisualizer\n",
        "from scipy.cluster.hierarchy import linkage\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from sklearn.decomposition import PCA\n",
        "from functools import reduce\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "bth9mz96T-3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = test.columns\n",
        "target = \"전화해지여부\"\n",
        "df= pd.concat([train, y], axis=1)"
      ],
      "metadata": {
        "id": "8HwGMcpoXQnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vyJgg8OQpMFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=8,n_init=25, max_iter = 600, random_state=1).fit(train[features])\n",
        "train[\"cluster_no\"] = kmeans.predict(train[features])\n",
        "test[\"cluster_no\"] = kmeans.predict(test[features])"
      ],
      "metadata": {
        "id": "-QLjUIIaCMp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "MrTMG14ZUOFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'max_depth': 6, 'learning_rate': 0.09051651936795661, 'n_estimators': 2372, 'reg_alpha': 0.676035385421549, 'reg_lambda': 2.1404742938810415}"
      ],
      "metadata": {
        "id": "_YSTAg2MUmL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "Yz_-pUjfVDJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"Y_LABEL\"] = train_df[\"전화해지여부\"]"
      ],
      "metadata": {
        "id": "lhK6b3sZVFoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop([\"전화해지여부\"],axis = 1)"
      ],
      "metadata": {
        "id": "eON4LwhDW0yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train,test,params,stratified,num_folds,drop_features,seed_num):\n",
        "\n",
        "    # start log\n",
        "    print('-'*50)\n",
        "    print('>> seed_num:',seed_num)\n",
        "    # print('>> drop_features:',len(drop_features))\n",
        "\n",
        "    seed_everything(1)\n",
        "\n",
        "    # Divide in training/validation and test data\n",
        "    train_df = train.copy()\n",
        "    test_df = test.copy()\n",
        "\n",
        "    # set training options\n",
        "    stratified = stratified\n",
        "    num_folds = num_folds\n",
        "\n",
        "    # Cross validation model\n",
        "    if stratified:\n",
        "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1)\n",
        "    else:\n",
        "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1)\n",
        "\n",
        "\n",
        "# LightGBM parameters found by Bayesian optimization\n",
        "        clf = LGBMClassifier(\n",
        "           max_depth: 6,\n",
        "           learning_rate: 0.09051651936795661,\n",
        "           n_estimators: 2372,\n",
        "           reg_alpha: 0.676035385421549,\n",
        "           reg_lambda: 2.1404742938810415\n",
        "        )\n",
        "\n",
        "        with warnings.catch_warnings():\n",
        "\n",
        "            warnings.filterwarnings('ignore')\n",
        "\n",
        "            clf.fit(\n",
        "                  train_x\n",
        "                , train_y\n",
        "                , eval_set=[(train_x, train_y), (valid_x, valid_y)]\n",
        "                , eval_metric= 'auc'\n",
        "                , verbose= -1\n",
        "                , early_stopping_rounds= 500\n",
        "            )\n",
        "\n",
        "        oof_preds_lgb[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
        "        sub_preds_lgb += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
        "\n",
        "        fold_importance_df = pd.DataFrame()\n",
        "        fold_importance_df[\"feature\"] = feats\n",
        "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
        "        fold_importance_df[\"fold\"] = n_fold + 1\n",
        "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
        "        # print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds_lgb[valid_idx])))\n",
        "\n",
        "    print('Full AUC score %.6f' % roc_auc_score(train_df['Y_LABEL'], oof_preds_lgb))\n",
        "\n",
        "    # Write submission file and plot feature importance\n",
        "    test_df['Y_LABEL_lgb'] = sub_preds_lgb\n",
        "\n",
        "    # vi\n",
        "    # print('-'*50)\n",
        "    # display(feature_importance_df.groupby(['feature'])['importance'].sum().sort_values(ascending=False).head(30))\n",
        "    # print('-'*50)\n",
        "    # display_importances(feature_importance_df)\n",
        "\n",
        "    # train auc\n",
        "    oof_auc = roc_auc_score(train_df['Y_LABEL'], oof_preds_lgb)\n",
        "\n",
        "\n",
        "    if oof_auc>=0.701:\n",
        "\n",
        "        # find the best thred for f1-score\n",
        "        f1_score_df = pd.DataFrame()\n",
        "        for thred in [i/10000 for i in range(0,10000,1) if (i/10000>0.1) & (i/10000<0.35)]:\n",
        "\n",
        "            a1 = pd.DataFrame()\n",
        "            f1 = f1_score(train_df['Y_LABEL'], np.where(oof_preds_lgb>thred,1,0), average='macro')\n",
        "            a1['f1'] = [f1]\n",
        "            a1['thred'] = [thred]\n",
        "            f1_score_df = pd.concat([f1_score_df, a1], axis=0)\n",
        "\n",
        "        thred = f1_score_df.loc[f1_score_df['f1']==f1_score_df['f1'].max(),'thred'].tolist()[0]\n",
        "        print('thred:',thred)\n",
        "        print('ncol',len(feats))\n",
        "\n",
        "        # train f1\n",
        "        print('auc:',oof_auc)\n",
        "        oof_f1 = f1_score(train_df['Y_LABEL'], np.where(oof_preds_lgb>thred,1,0), average='macro')\n",
        "        print('f1:',oof_f1)\n",
        "        a1 = train_df['Y_LABEL'].value_counts()/len(train_df)\n",
        "        print('Target ratio(real):',(a1[1]))\n",
        "\n",
        "        # test err\n",
        "        test_df['TARGET'] = np.where(test_df['Y_LABEL_lgb']>thred,1,0)\n",
        "        a1 = test_df['TARGET'].value_counts()/len(test_df)\n",
        "        print('Target ratio(pred):',(a1[1]))\n",
        "        target_sum = test_df['TARGET'].sum()\n",
        "        print('Target sum:',target_sum)\n",
        "\n",
        "\n",
        "    return test_df,oof_f1"
      ],
      "metadata": {
        "id": "7-dUy4WvUlwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FJOdoYt2sd3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본 변수 모두에다가 유의한 로지스틱 회귀 2차교호작용항 다 더해서"
      ],
      "metadata": {
        "id": "Z29bwrwsGxnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.loc[train[\"음성사서함이용\"] <=0,\"count\"] =0\n",
        "train.loc[(train[\"음성사서함이용\"]>0)& (train[\"음성사서함이용\"]<=22),'count'] = 1\n",
        "train.loc[train[\"음성사서함이용\"]>22,'count'] = 2"
      ],
      "metadata": {
        "id": "tT87yZFhseZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.loc[train[\"음성사서함이용\"] <=0,\"count\"] =0\n",
        "test.loc[(train[\"음성사서함이용\"]>0)& (train[\"음성사서함이용\"]<=22),'count'] = 1\n",
        "test.loc[train[\"음성사서함이용\"]>22,'count'] = 2"
      ],
      "metadata": {
        "id": "i4fWAfKKup3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.describe()"
      ],
      "metadata": {
        "id": "wrIBuYXtuctH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.describe()"
      ],
      "metadata": {
        "id": "hXh1vebsg29V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_cols = [\"count\"]\n",
        "test = pd.get_dummies(test, columns = dummy_cols)\n",
        "test"
      ],
      "metadata": {
        "id": "oG1L6ZKUu5ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# onehot encoding - train\n",
        "\n",
        "dummy_cols = [\"count\"]\n",
        "train = pd.get_dummies(train, columns = dummy_cols)\n",
        "train"
      ],
      "metadata": {
        "id": "BYY5yHwFueHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = train.columns"
      ],
      "metadata": {
        "id": "zG1RCXuzvyaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = features.drop([\"count_0.0\",\"count_1.0\",\"count_2.0\"])"
      ],
      "metadata": {
        "id": "c2rbWBJfv1Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling - train\n",
        "\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train[features] = scaler.fit_transform(train[features])"
      ],
      "metadata": {
        "id": "7vniuha4vDWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Scaling - test\n",
        "\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "test[features] = scaler.fit_transform(test[features])"
      ],
      "metadata": {
        "id": "TxyLSQN6vgUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "E5aJAx67wImm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "yeSumO9QwJ8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "불균형 샘ㅈ플링"
      ],
      "metadata": {
        "id": "b_mX2ALGwYLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#case4\n",
        "train_x, test_x, train_y, test_y = train_test_split(train, y, test_size = 0.2,\n",
        "                                                    stratify = y, random_state = 0)\n",
        "\n",
        "\n",
        "smoteto = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
        "x_tomek, y_tomek = smoteto.fit_resample(train_x, train_y)\n",
        "\n",
        "lgbm = LGBMC(max_depth= 10, n_estimators= 700,\n",
        "             num_leaves= 1600, subsample= 0.8, random_state=0)\n",
        "lgbm.fit(x_tomek, y_tomek)\n",
        "\n",
        "train_pred = lgbm.predict(x_tomek)\n",
        "test_pred = lgbm.predict(test_x)\n",
        "\n",
        "case_4 = metrics.f1_score(test_y, test_pred, average='macro')\n",
        "\n",
        "print(round(case_4, 4))"
      ],
      "metadata": {
        "id": "4mQgqXUcwKgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tomek"
      ],
      "metadata": {
        "id": "Qksn1baUwmqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#case\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(train, y, test_size = 0.2,\n",
        "                                                    stratify = y, random_state = 0)\n",
        "lgbm = LGBMC(max_depth= 10, n_estimators= 700,\n",
        "             num_leaves= 1600, subsample= 0.8, random_state=0)\n",
        "lgbm.fit(train_x, train_y)\n",
        "\n",
        "train_pred = lgbm.predict(train_x)\n",
        "test_pred = lgbm.predict(test_x)\n",
        "\n",
        "case_1 = metrics.f1_score(test_y, test_pred, average='macro')\n",
        "print(round(case_1, 4))"
      ],
      "metadata": {
        "id": "1Lv-mhupxYZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "불균형샘플링 사용하기로 결정"
      ],
      "metadata": {
        "id": "ETk7OVYXxvUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smoteto = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
        "x_tomek, y_tomek = smoteto.fit_resample(train, y)"
      ],
      "metadata": {
        "id": "GeO3P4DHxoov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train= x_tomek\n",
        "y= y_tomek\n"
      ],
      "metadata": {
        "id": "DMewRzEBx2ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "f1ZCkCOix9Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "q2SZ03Scx9nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "X9uWUDemx-LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import optuna\n",
        "from optuna import Trial, visualization\n",
        "from optuna.samplers import TPESampler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "zptSWYWcx-qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_all(seed: int = 1930):\n",
        "\n",
        "    print(\"Using Seed Number {}\".format(seed))\n",
        "\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(\n",
        "        seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(\n",
        "        seed)\n",
        "\n",
        "\n",
        "def seed_worker(_worker_id):\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "seed_all(seed=1994)"
      ],
      "metadata": {
        "id": "PhOlRQCFyzbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oE0BpJGGyoe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_74EuZqiyqNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "clf =  RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
        "# clf =  AdaBoostClassifier()"
      ],
      "metadata": {
        "id": "oHVU7fIoyqPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_final = test\n",
        "X_train_final = train\n",
        "y"
      ],
      "metadata": {
        "id": "v_UzsnRBz3Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = X_train_final.values\n",
        "test_X = X_test_final.values\n",
        "trai"
      ],
      "metadata": {
        "id": "4ScnO_3uz3L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y"
      ],
      "metadata": {
        "id": "C6GnroQp0v0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wubWbaXj0tHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RF_objective(trial):\n",
        "    max_depth = trial.suggest_int('max_depth', 2, 10)\n",
        "    n_estimators =  trial.suggest_int('n_estimators', 100, 1000),\n",
        "    max_features = 1\n",
        "\n",
        "    model = RandomForestClassifier(max_depth = max_depth,n_estimators = n_estimators,n_jobs=2,random_state=25)\n",
        "\n",
        "\n",
        "    model.fit(train_X, train_y)\n",
        "    score = cross_val_score(model, train_X, train_y, cv=5, scoring=\"f1\")\n",
        "    f1_mean = score.mean()\n",
        "\n",
        "    return f1_mean\n",
        "\n",
        "#Execute optuna and set hyperparameters\n",
        "RF_study = optuna.create_study(direction='maximize')\n",
        "RF_study.optimize(RF_objective, n_trials=200)\n",
        "\n",
        "#Create an instance with tuned hyperparameters\n",
        "optimized_RF = RandomForestClassifier(max_depth = RF_study.best_params['max_depth'], max_leaf_nodes = RF_study.best_params['max_leaf_nodes'],\n",
        "                                      n_estimators = RF_study.best_params['n_estimators'],n_jobs=2,random_state=25)"
      ],
      "metadata": {
        "id": "AXiTEmC4yv3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = train.columns\n",
        "target = \"전화해지여부\"\n",
        "df= pd.concat([train, y], axis=1)\n",
        "\n",
        "df_trains = []\n",
        "df_valids = []\n",
        "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
        "for train_index, valid_index in skf.split(df[features], df[target]):\n",
        "    df_train = df.loc[train_index]\n",
        "    df_valid = df.loc[valid_index]\n",
        "    df_trains.append(df_train)\n",
        "    df_valids.append(df_valid)\n",
        "def accuracy(true, pred):\n",
        "    return np.mean(true==pred)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 2, 10, step=1, log=False),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 10, 100 , log=True),\n",
        "        'max_features' :1,\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    score = []\n",
        "    for df_train, df_valid in zip(df_trains, df_valids):\n",
        "        clf = RandomForestClassifier(**params)\n",
        "        clf.fit(df_train[features], df_train[target])\n",
        "        pred = clf.predict(df_valid[features])\n",
        "        true = df_valid[target].values\n",
        "        score.append(accuracy(true, pred))\n",
        "    score = np.mean(score)\n",
        "    return score\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=0), pruner=SuccessiveHalvingPruner())\n",
        "study.optimize(objective, n_trials=200)"
      ],
      "metadata": {
        "id": "lqkPersC1Nc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = []\n",
        "for df_train in df_trains:\n",
        "    clf = RandomForestClassifier(**study.best_params)\n",
        "    clf.fit(df_train[features], df_train[target])\n",
        "    clfs.append(clf)\n",
        "\n",
        "# 테스트 데이터 불러오기\n",
        "df_test = test\n",
        "\n",
        "\n",
        "# 예측 수행 (soft voting)\n",
        "pred = [clf.predict_proba(df_test[features]) for clf in clfs]\n",
        "pred = np.mean(pred, axis=0)\n",
        "pred = np.argmax(pred, axis=1)\n"
      ],
      "metadata": {
        "id": "9mrjVOQd26NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "vpDOZgf_8ddY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_submission = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "df_submission['전화해지여부'] = pred\n",
        "df_submission.to_csv('random_optuna15.csv',index=False)"
      ],
      "metadata": {
        "id": "sJOxIun33TW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission[\"전화해지여부\"].sum()"
      ],
      "metadata": {
        "id": "M2nCbpZm8hhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission"
      ],
      "metadata": {
        "id": "etz7Pku-8llQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = train.columns\n",
        "target = \"전화해지여부\"\n",
        "df= pd.concat([train, y], axis=1)\n",
        "\n",
        "df_trains = []\n",
        "df_valids = []\n",
        "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
        "for train_index, valid_index in skf.split(df[features], df[target]):\n",
        "    df_train = df.loc[train_index]\n",
        "    df_valid = df.loc[valid_index]\n",
        "    df_trains.append(df_train)\n",
        "    df_valids.append(df_valid)\n",
        "def accuracy(true, pred):\n",
        "    return np.mean(true==pred)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 2, 12, step=1, log=False),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 5000 , log=True),\n",
        "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 10.0),\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    score = []\n",
        "    for df_train, df_valid in zip(df_trains, df_valids):\n",
        "        clf = LGBMClassifier(**params)\n",
        "        clf.fit(df_train[features], df_train[target])\n",
        "        pred = clf.predict(df_valid[features])\n",
        "        true = df_valid[target].values\n",
        "        score.append(accuracy(true, pred))\n",
        "    score = np.mean(score)\n",
        "    return score\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=0), pruner=SuccessiveHalvingPruner())\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "id": "KKGQVk4q8s4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{'max_depth': 8, 'learning_rate': 0.06316568334735269, 'n_estimators': 4653, 'reg_alpha': 0.8770706039368489, 'reg_lambda': 5.928827999755667}"
      ],
      "metadata": {
        "id": "yRk4iv_U0YR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = []\n",
        "for df_train in df_trains:\n",
        "    clf = LGBMClassifier(**study.best_params)\n",
        "    clf.fit(df_train[features], df_train[target])\n",
        "    clfs.append(clf)\n",
        "\n",
        "# 테스트 데이터 불러오기\n",
        "df_test = test\n",
        "\n",
        "\n",
        "# 예측 수행 (soft voting)\n",
        "pred = [clf.predict_proba(df_test[features]) for clf in clfs]\n",
        "pred = np.mean(pred, axis=0)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o6ZY6oMbux_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission.sum()"
      ],
      "metadata": {
        "id": "J-XIhI5q0sR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "df_submission['전화해지여부'] = pred\n",
        "df_submission.to_csv('light_optuna16.csv',index=False)"
      ],
      "metadata": {
        "id": "DyBNd9qV0kXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm = LGBMC(max_depth= 9, n_estimators= 2500 ,\n",
        "            reg_alpha = 0.8770706039, random_state=42, reg_lambda = 5.9288279997,\n",
        "             learning_rate = 0.06316568334)\n",
        "lgbm.fit(train, y)\n",
        "\n",
        "test_pred2 = lgbm.predict(test)\n"
      ],
      "metadata": {
        "id": "_eyFAhrX0_w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred.sum()"
      ],
      "metadata": {
        "id": "_oDgCh1114Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred1.sum()"
      ],
      "metadata": {
        "id": "vGSDkHpg2BXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred2.sum()"
      ],
      "metadata": {
        "id": "N9Sx9OVq2KF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{'max_depth': 8, 'learning_rate': 0.06316568334735269, 'n_estimators': 4653, 'reg_alpha': 0.8770706039368489, 'reg_lambda': 5.928827999755667}"
      ],
      "metadata": {
        "id": "mPsV5UrW1DRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "df_submission['전화해지여부'] = test_pred\n",
        "df_submission.to_csv('light_optuna17.csv',index=False)"
      ],
      "metadata": {
        "id": "TvcQ1Bow2S-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "from supervised.automl import AutoML\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "I8nP97LX2WeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervised.automl"
      ],
      "metadata": {
        "id": "-ZNGMyGM5BjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mljar-supervised\n"
      ],
      "metadata": {
        "id": "IqYqe0Dz5FYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install auto-sklearn"
      ],
      "metadata": {
        "id": "TQ0CMw805mwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo pip install auto-sklearn"
      ],
      "metadata": {
        "id": "B-gjXJwl6AFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "seed_everything(42) # Seed 고정"
      ],
      "metadata": {
        "id": "yuKkcZNC8JC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "rppCZ2He8yZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/test.csv')\n"
      ],
      "metadata": {
        "id": "wYob1lM88jHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train.drop(['ID', '전화해지여부'], axis = 1)\n",
        "y_train = train['전화해지여부']\n",
        "test = test.drop('ID', axis = 1)\n"
      ],
      "metadata": {
        "id": "gIvKgy3g8jaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f0MG6Lul8tiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cSHauLKD81qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "a7TTU6CF838R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(\"/content/drive/MyDrive/sample_submission.csv\")\n",
        "submission.iloc[:, 1] = pred\n",
        "submission.to_csv(\"automl_7.csv\", index=False)"
      ],
      "metadata": {
        "id": "nul29MT185fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hleAzjRs9vlR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}